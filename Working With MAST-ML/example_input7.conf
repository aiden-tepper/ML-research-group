# You run this with
# python3 -m mastml.mastml_driver mastml/tests/conf/example_input.conf mastml/tests/csv/example_data.xlsx -o results/example_results

[GeneralSetup]
    input_features = Auto
    input_target = Scaled activation energy (eV)
    randomizer = False
    metrics = Auto
    input_other = Material composition, Host element, Solute element, predict_Pt
    input_grouping = Host element
    input_testdata = predict_Pt

#[DataCleaning]
#    cleaning_method = imputation
#    imputation_strategy = mean

[FeatureNormalization]
    [[StandardScaler]]

#[FeatureGeneration]
#    [[Magpie]]
#        composition_feature = Solute element
#        feature_types = composition_avg, arithmetic_avg, max, min, difference, elements

#[FeatureSelection]
#    [[MASTMLFeatureSelector]]
#        n_features_to_select = 3
#        cv = LeaveOneGroupOut_select
#        estimator = KernelRidge_select

[DataSplits]
    [[NoSplit]]
    [[RepeatedKFold]]
        n_splits = 5
        n_repeats = 2
    [[LeaveOneGroupOut_select]]
        grouping_column = Host element

[Models]
#	[[GaussianProcessRegressor]]
#	[[RandomForestRegressor]]
	[[KernelRidge]]
     		alpha = 0.034
		gamma = 0.138
		kernel = rbf
#	[[KernelRidge_select]]
# 		alpha = 1
#		gamma = 1
#		kernel = rbf

[MiscSettings]
    plot_target_histogram = True
    plot_train_test_plots = True
    plot_predicted_vs_true = True
    plot_predicted_vs_true_average = True
    plot_best_worst_per_point = True
    plot_each_feature_vs_target = False
    plot_error_plots = True
    rf_error_method = stdev
    rf_error_percentile = 95
    normalize_target_feature = False

#[HyperOpt]
#    [[GridSearch]]
#        estimator = KernelRidge
#        cv = RepeatedKFold
#        param_names = alpha ; gamma
#        param_values = -5 5 100 log float ; -5 5 100 log float
#        scoring = root_mean_squared_error
