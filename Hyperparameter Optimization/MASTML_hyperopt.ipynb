{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"MASTML_hyperopt.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"VdLbblbT3fIB"},"source":["# MAST-ML Hyperparameter Optimization Activity\n","\n","\n","---\n","This activity serves as a way to learn more about hyperparameter optimization. This notebook builds of of the notebook used in the \"MASTML Workflows\" activity so the first half or so is the same as we setup the dataset.\n","\n","During the activity we'll be working with the MLPregressor model from scikit-learn. It may be useful to have the documentation for that model open as a reference as it will inform our decision making along the way.\n","\n","The overall goal is to explore how we might go from the default MLPregressor provided by scikit-learn to a model that we think is performing the best for our data.\n","\n","**Note: all sections before section 5 are the same as the \"workflow activity\" so if you've worked through that recently feel free to execute those and skip over the details if you already know what's going on. Notice how with this setup to using mastml we can copy paste previous notebooks to build off of previous ideas and explore new concepts.**"]},{"cell_type":"markdown","metadata":{"id":"6UxJ6oB54hv9"},"source":["## Section 1: Setting up our Google Colab Environment\n","---\n","Before running any code we first need to install MAST-ML as well as it's dependencies into the colab environment. \n"]},{"cell_type":"markdown","metadata":{"id":"_pB0qEmM48BY"},"source":["Clone the MAST-ML code into the content directory to the left. You should be able to see a new \"MAST-ML\" directory after running this cell."]},{"cell_type":"code","metadata":{"id":"xdEXmdzP7kWN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618305836344,"user_tz":-330,"elapsed":10919,"user":{"displayName":"AGAM GOYAL","photoUrl":"","userId":"12333294385015277225"}},"outputId":"e20df204-d538-4ff8-8a74-e4fc46ea295b"},"source":["!git clone --single-branch --branch skunkworks_s21 https://github.com/uw-cmg/MAST-ML"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Cloning into 'MAST-ML'...\n","remote: Enumerating objects: 344, done.\u001b[K\n","remote: Counting objects: 100% (344/344), done.\u001b[K\n","remote: Compressing objects: 100% (80/80), done.\u001b[K\n","remote: Total 18544 (delta 279), reused 300 (delta 258), pack-reused 18200\u001b[K\n","Receiving objects: 100% (18544/18544), 131.39 MiB | 22.63 MiB/s, done.\n","Resolving deltas: 100% (12340/12340), done.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"HcruaZzR5T-V"},"source":["Next, we install the required dependencies of MAST-ML to our Colab session"]},{"cell_type":"code","metadata":{"id":"hqhQ2pXcvCwU","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1618306037813,"user_tz":-330,"elapsed":116660,"user":{"displayName":"AGAM GOYAL","photoUrl":"","userId":"12333294385015277225"}},"outputId":"e6003d8e-7054-4d1c-8650-fdfe911fc6d7"},"source":["!pip install -r MAST-ML/requirements.txt\n","!pip install pymatgen==2020.12.31\n","#!pip install scikit-learn=='0.23.2'"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Collecting citrination-client\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/61/49/c0af91084172f6a6aa7d625651ec366c85a4fd717c5b4fa0e014d1953d6e/citrination-client-6.5.1.tar.gz (54kB)\n","\u001b[K     |████████████████████████████████| 61kB 3.7MB/s \n","\u001b[?25hCollecting dlhub_sdk\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/cd/02ad247cf7df4467b63dec57e2c8d8f5fe64330bf6da61e6ac6cddcde149/dlhub_sdk-0.9.4-py2.py3-none-any.whl (41kB)\n","\u001b[K     |████████████████████████████████| 51kB 3.8MB/s \n","\u001b[?25hCollecting globus_nexus_client\n","  Downloading https://files.pythonhosted.org/packages/52/ca/a0e2c03aeea3e4b3b3256ab309e24fb5227ebaf92aabca56b6dfc3cc758a/globus_nexus_client-0.3.0-py2.py3-none-any.whl\n","Collecting globus_sdk\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/92/a4/57b628cc5509eeb8361eb87506a3aea2078ca9c4e4ffaebc88280cdf7f40/globus_sdk-2.0.1-py2.py3-none-any.whl (85kB)\n","\u001b[K     |████████████████████████████████| 92kB 5.5MB/s \n","\u001b[?25hCollecting matminer\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/18/67/319db03366448bf367f6239598da2da0021389b02a7f874380ee3c193890/matminer-0.6.5.tar.gz (5.8MB)\n","\u001b[K     |████████████████████████████████| 5.8MB 6.7MB/s \n","\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from -r MAST-ML/requirements.txt (line 6)) (3.2.2)\n","Collecting mdf_forge\n","  Downloading https://files.pythonhosted.org/packages/6f/0c/697e48caaabc83e071c222dc6d25ec0a924c69d4cf8f990964f47091b8d2/mdf_forge-0.7.6-py2.py3-none-any.whl\n","Collecting mdf-toolbox\n","  Downloading https://files.pythonhosted.org/packages/f5/44/45ed3b256d744891384d13088c12a23baaa2e395b341c3ab03c18001f715/mdf_toolbox-0.5.7-py2.py3-none-any.whl\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from -r MAST-ML/requirements.txt (line 9)) (1.19.5)\n","Requirement already satisfied: openpyxl in /usr/local/lib/python3.7/dist-packages (from -r MAST-ML/requirements.txt (line 10)) (2.5.9)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from -r MAST-ML/requirements.txt (line 11)) (1.1.5)\n","Collecting pymatgen\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b4/db/c1891589a2b3133658f58c883eda4ff25769036363f662e1af5d3ed1394c/pymatgen-2022.0.5.tar.gz (3.4MB)\n","\u001b[K     |████████████████████████████████| 3.4MB 44.6MB/s \n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n","    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from -r MAST-ML/requirements.txt (line 13)) (0.22.2.post1)\n","Collecting scikit-optimize\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8b/03/be33e89f55866065a02e515c5b319304a801a9f1027a9b311a9b1d1f8dc7/scikit_optimize-0.8.1-py2.py3-none-any.whl (101kB)\n","\u001b[K     |████████████████████████████████| 102kB 7.4MB/s \n","\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from -r MAST-ML/requirements.txt (line 15)) (1.4.1)\n","Collecting sphinx-automodapi\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/16/08/83a3ee2cd420043538d195f024caac76dc2567a266361d95bb9344ab5594/sphinx_automodapi-0.13-py3-none-any.whl (75kB)\n","\u001b[K     |████████████████████████████████| 81kB 5.6MB/s \n","\u001b[?25hRequirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.7/dist-packages (from citrination-client->-r MAST-ML/requirements.txt (line 1)) (2.23.0)\n","Collecting pypif\n","  Downloading https://files.pythonhosted.org/packages/1e/04/a59e5ebacaed2800678467d9fcf511d249bac9b1b692a8fba0072cb09a49/pypif-2.1.2.tar.gz\n","Requirement already satisfied: six<2 in /usr/local/lib/python3.7/dist-packages (from citrination-client->-r MAST-ML/requirements.txt (line 1)) (1.15.0)\n","Collecting pyyaml>=5.1.2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7a/a5/393c087efdc78091afa2af9f1378762f9821c9c1d7a22c5753fb5ac5f97a/PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636kB)\n","\u001b[K     |████████████████████████████████| 645kB 33.3MB/s \n","\u001b[?25hCollecting jsonschema>=3.2.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c5/8f/51e89ce52a085483359217bc72cdbf6e75ee595d5b1d4b5ade40c7e018b8/jsonschema-3.2.0-py2.py3-none-any.whl (56kB)\n","\u001b[K     |████████████████████████████████| 61kB 4.5MB/s \n","\u001b[?25hCollecting funcx>=0.0.5\n","  Downloading https://files.pythonhosted.org/packages/eb/1c/79404da8ff1aabe8d1619905cbfe376d4128bfdd0904fba992c7f732e86a/funcx-0.2.0-py3-none-any.whl\n","Collecting pyjwt[crypto]<2.0.0,>=1.5.3\n","  Downloading https://files.pythonhosted.org/packages/87/8b/6a9f14b5f781697e51259d81657e6048fd31a113229cf346880bb7545565/PyJWT-1.7.1-py2.py3-none-any.whl\n","Collecting tqdm>=4.46.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/72/8a/34efae5cf9924328a8f34eeb2fdaae14c011462d9f0e3fcded48e1266d1c/tqdm-4.60.0-py2.py3-none-any.whl (75kB)\n","\u001b[K     |████████████████████████████████| 81kB 5.7MB/s \n","\u001b[?25hRequirement already satisfied: pymongo>=3.10.1 in /usr/local/lib/python3.7/dist-packages (from matminer->-r MAST-ML/requirements.txt (line 5)) (3.11.3)\n","Collecting pint>=0.11\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/33/de/53a77b82553579affab7438d299f850acbc1c4dd741c5ce52594513cb0ef/Pint-0.17-py2.py3-none-any.whl (204kB)\n","\u001b[K     |████████████████████████████████| 215kB 46.2MB/s \n","\u001b[?25hCollecting plotly>=4.8.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1f/f6/bd3c17c8003b6641df1228e80e1acac97ed8402635e46c2571f8e1ef63af/plotly-4.14.3-py2.py3-none-any.whl (13.2MB)\n","\u001b[K     |████████████████████████████████| 13.2MB 41.9MB/s \n","\u001b[?25hCollecting future>=0.18.2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/45/0b/38b06fd9b92dc2b68d58b75f900e97884c45bedd2ff83203d933cf5851c9/future-0.18.2.tar.gz (829kB)\n","\u001b[K     |████████████████████████████████| 829kB 43.4MB/s \n","\u001b[?25hRequirement already satisfied: sympy>=1.6 in /usr/local/lib/python3.7/dist-packages (from matminer->-r MAST-ML/requirements.txt (line 5)) (1.7.1)\n","Collecting monty>=3.0.2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/41/47/e6f045cd69f24df0b4ddd55fab329c079b7c9ce978a32431dce904f6a1d6/monty-2021.3.3-py3-none-any.whl (63kB)\n","\u001b[K     |████████████████████████████████| 71kB 5.2MB/s \n","\u001b[?25hRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r MAST-ML/requirements.txt (line 6)) (1.3.1)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r MAST-ML/requirements.txt (line 6)) (2.4.7)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r MAST-ML/requirements.txt (line 6)) (0.10.0)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r MAST-ML/requirements.txt (line 6)) (2.8.1)\n","Collecting fair-research-login>=0.1.5\n","  Downloading https://files.pythonhosted.org/packages/89/a6/3239efa5150d9cb52af90d246ca46a405eefdaee503e77bf84023dbd2752/fair_research_login-0.2.0-py2.py3-none-any.whl\n","Requirement already satisfied: jdcal in /usr/local/lib/python3.7/dist-packages (from openpyxl->-r MAST-ML/requirements.txt (line 10)) (1.4.1)\n","Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.7/dist-packages (from openpyxl->-r MAST-ML/requirements.txt (line 10)) (1.0.1)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->-r MAST-ML/requirements.txt (line 11)) (2018.9)\n","Collecting uncertainties>=3.1.4\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/45/41/fc7e7b73b603e7c2c9e040b7aa8caf4a88d74b6faa567601ed82b6f0d8e1/uncertainties-3.1.5-py2.py3-none-any.whl (246kB)\n","\u001b[K     |████████████████████████████████| 256kB 44.7MB/s \n","\u001b[?25hRequirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from pymatgen->-r MAST-ML/requirements.txt (line 12)) (0.8.9)\n","Requirement already satisfied: typing-extensions>=3.7.4.3; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from pymatgen->-r MAST-ML/requirements.txt (line 12)) (3.7.4.3)\n","Collecting ruamel.yaml>=0.15.6\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/29/4e/c3105bbbbc662f6a671a505f00ec771e93b5254f09fbb06002af9087071a/ruamel.yaml-0.17.4-py3-none-any.whl (101kB)\n","\u001b[K     |████████████████████████████████| 102kB 7.6MB/s \n","\u001b[?25hRequirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.7/dist-packages (from pymatgen->-r MAST-ML/requirements.txt (line 12)) (2.5)\n","Collecting spglib>=1.9.9.44\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4b/98/fa4760b9c71e2eace5a60b85dbf36dece49c379f8291cf1203056f287766/spglib-1.16.1-cp37-cp37m-manylinux2010_x86_64.whl (296kB)\n","\u001b[K     |████████████████████████████████| 296kB 50.2MB/s \n","\u001b[?25hRequirement already satisfied: palettable>=3.1.1 in /usr/local/lib/python3.7/dist-packages (from pymatgen->-r MAST-ML/requirements.txt (line 12)) (3.3.0)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->-r MAST-ML/requirements.txt (line 13)) (1.0.1)\n","Collecting pyaml>=16.9\n","  Downloading https://files.pythonhosted.org/packages/15/c4/1310a054d33abc318426a956e7d6df0df76a6ddfa9c66f6310274fb75d42/pyaml-20.4.0-py2.py3-none-any.whl\n","Requirement already satisfied: sphinx>=1.7 in /usr/local/lib/python3.7/dist-packages (from sphinx-automodapi->-r MAST-ML/requirements.txt (line 16)) (1.8.5)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->citrination-client->-r MAST-ML/requirements.txt (line 1)) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->citrination-client->-r MAST-ML/requirements.txt (line 1)) (2020.12.5)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->citrination-client->-r MAST-ML/requirements.txt (line 1)) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->citrination-client->-r MAST-ML/requirements.txt (line 1)) (2.10)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.2.0->dlhub_sdk->-r MAST-ML/requirements.txt (line 2)) (54.2.0)\n","Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.2.0->dlhub_sdk->-r MAST-ML/requirements.txt (line 2)) (20.3.0)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.2.0->dlhub_sdk->-r MAST-ML/requirements.txt (line 2)) (3.8.1)\n","Requirement already satisfied: pyrsistent>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.2.0->dlhub_sdk->-r MAST-ML/requirements.txt (line 2)) (0.17.3)\n","Collecting configobj\n","  Downloading https://files.pythonhosted.org/packages/64/61/079eb60459c44929e684fa7d9e2fdca403f67d64dd9dbac27296be2e0fab/configobj-5.0.6.tar.gz\n","Requirement already satisfied: dill>=0.3 in /usr/local/lib/python3.7/dist-packages (from funcx>=0.0.5->dlhub_sdk->-r MAST-ML/requirements.txt (line 2)) (0.3.3)\n","Collecting texttable\n","  Downloading https://files.pythonhosted.org/packages/06/f5/46201c428aebe0eecfa83df66bf3e6caa29659dbac5a56ddfd83cae0d4a4/texttable-1.6.3-py2.py3-none-any.whl\n","Collecting parsl>=1.1.0a0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/41/2e/33f0b66ee8afe2af0cffd103cffb487c7616a16a2e77f0e1635238b69dfd/parsl-1.1.0a1-py3-none-any.whl (449kB)\n","\u001b[K     |████████████████████████████████| 450kB 55.0MB/s \n","\u001b[?25hRequirement already satisfied: pyzmq>=22.0.0 in /usr/local/lib/python3.7/dist-packages (from funcx>=0.0.5->dlhub_sdk->-r MAST-ML/requirements.txt (line 2)) (22.0.3)\n","Collecting python-daemon\n","  Downloading https://files.pythonhosted.org/packages/b1/cc/2ab0d910548de45eaaa50d0372387951d9005c356a44c6858db12dc6b2b7/python_daemon-2.3.0-py2.py3-none-any.whl\n","Collecting typer>=0.3.0\n","  Downloading https://files.pythonhosted.org/packages/90/34/d138832f6945432c638f32137e6c79a3b682f06a63c488dcfaca6b166c64/typer-0.3.2-py3-none-any.whl\n","Collecting cryptography>=1.4; extra == \"crypto\"\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b2/26/7af637e6a7e87258b963f1731c5982fb31cd507f0d90d91836e446955d02/cryptography-3.4.7-cp36-abi3-manylinux2014_x86_64.whl (3.2MB)\n","\u001b[K     |████████████████████████████████| 3.2MB 34.1MB/s \n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from pint>=0.11->matminer->-r MAST-ML/requirements.txt (line 5)) (20.9)\n","Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.7/dist-packages (from plotly>=4.8.1->matminer->-r MAST-ML/requirements.txt (line 5)) (1.3.3)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.7/dist-packages (from sympy>=1.6->matminer->-r MAST-ML/requirements.txt (line 5)) (1.2.1)\n","Collecting ruamel.yaml.clib>=0.1.2; platform_python_implementation == \"CPython\" and python_version < \"3.10\"\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5e/6e/f652c56bbb2c3d3fca252ffc7c0358597f57a1bbdf484dac683054950c63/ruamel.yaml.clib-0.2.2-cp37-cp37m-manylinux1_x86_64.whl (547kB)\n","\u001b[K     |████████████████████████████████| 552kB 39.4MB/s \n","\u001b[?25hRequirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from networkx>=2.2->pymatgen->-r MAST-ML/requirements.txt (line 12)) (4.4.2)\n","Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.7->sphinx-automodapi->-r MAST-ML/requirements.txt (line 16)) (0.7.12)\n","Requirement already satisfied: babel!=2.0,>=1.3 in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.7->sphinx-automodapi->-r MAST-ML/requirements.txt (line 16)) (2.9.0)\n","Requirement already satisfied: Pygments>=2.0 in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.7->sphinx-automodapi->-r MAST-ML/requirements.txt (line 16)) (2.6.1)\n","Requirement already satisfied: docutils>=0.11 in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.7->sphinx-automodapi->-r MAST-ML/requirements.txt (line 16)) (0.16)\n","Requirement already satisfied: snowballstemmer>=1.1 in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.7->sphinx-automodapi->-r MAST-ML/requirements.txt (line 16)) (2.1.0)\n","Requirement already satisfied: sphinxcontrib-websupport in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.7->sphinx-automodapi->-r MAST-ML/requirements.txt (line 16)) (1.2.4)\n","Requirement already satisfied: Jinja2>=2.3 in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.7->sphinx-automodapi->-r MAST-ML/requirements.txt (line 16)) (2.11.3)\n","Requirement already satisfied: imagesize in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.7->sphinx-automodapi->-r MAST-ML/requirements.txt (line 16)) (1.2.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->jsonschema>=3.2.0->dlhub_sdk->-r MAST-ML/requirements.txt (line 2)) (3.4.1)\n","Requirement already satisfied: tblib in /usr/local/lib/python3.7/dist-packages (from parsl>=1.1.0a0->funcx>=0.0.5->dlhub_sdk->-r MAST-ML/requirements.txt (line 2)) (1.7.0)\n","Collecting paramiko\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/95/19/124e9287b43e6ff3ebb9cdea3e5e8e88475a873c05ccdf8b7e20d2c4201e/paramiko-2.7.2-py2.py3-none-any.whl (206kB)\n","\u001b[K     |████████████████████████████████| 215kB 57.2MB/s \n","\u001b[?25hCollecting typeguard>=2.10\n","  Downloading https://files.pythonhosted.org/packages/06/1f/c10ad900a10e1421b85d20f1c9d1748469ef5a34296693a02be887af5f95/typeguard-2.12.0-py3-none-any.whl\n","Collecting psutil>=5.5.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/84/da/f7efdcf012b51506938553dbe302aecc22f3f43abd5cffa8320e8e0588d5/psutil-5.8.0-cp37-cp37m-manylinux2010_x86_64.whl (296kB)\n","\u001b[K     |████████████████████████████████| 296kB 40.3MB/s \n","\u001b[?25hCollecting lockfile>=0.10\n","  Downloading https://files.pythonhosted.org/packages/c8/22/9460e311f340cb62d26a38c419b1381b8593b0bb6b5d1f056938b086d362/lockfile-0.12.2-py2.py3-none-any.whl\n","Requirement already satisfied: click<7.2.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer>=0.3.0->funcx>=0.0.5->dlhub_sdk->-r MAST-ML/requirements.txt (line 2)) (7.1.2)\n","Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=1.4; extra == \"crypto\"->pyjwt[crypto]<2.0.0,>=1.5.3->globus_sdk->-r MAST-ML/requirements.txt (line 4)) (1.14.5)\n","Requirement already satisfied: sphinxcontrib-serializinghtml in /usr/local/lib/python3.7/dist-packages (from sphinxcontrib-websupport->sphinx>=1.7->sphinx-automodapi->-r MAST-ML/requirements.txt (line 16)) (1.1.4)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2>=2.3->sphinx>=1.7->sphinx-automodapi->-r MAST-ML/requirements.txt (line 16)) (1.1.1)\n","Collecting bcrypt>=3.1.3\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/26/70/6d218afbe4c73538053c1016dd631e8f25fffc10cd01f5c272d7acf3c03d/bcrypt-3.2.0-cp36-abi3-manylinux2010_x86_64.whl (63kB)\n","\u001b[K     |████████████████████████████████| 71kB 5.3MB/s \n","\u001b[?25hCollecting pynacl>=1.0.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9d/57/2f5e6226a674b2bcb6db531e8b383079b678df5b10cdaa610d6cf20d77ba/PyNaCl-1.4.0-cp35-abi3-manylinux1_x86_64.whl (961kB)\n","\u001b[K     |████████████████████████████████| 962kB 40.4MB/s \n","\u001b[?25hRequirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=1.4; extra == \"crypto\"->pyjwt[crypto]<2.0.0,>=1.5.3->globus_sdk->-r MAST-ML/requirements.txt (line 4)) (2.20)\n","Building wheels for collected packages: pymatgen\n","  Building wheel for pymatgen (PEP 517) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pymatgen: filename=pymatgen-2022.0.5-cp37-cp37m-linux_x86_64.whl size=3792009 sha256=92912e0ca7de09657965900d0bcf703e9dd19f5bc593b5d1c765a34ee5a75549\n","  Stored in directory: /root/.cache/pip/wheels/c7/6c/74/b93186a11fe286a09dc9230ddbe5816ab24405993bdfa7c20a\n","Successfully built pymatgen\n","Building wheels for collected packages: citrination-client, matminer, pypif, future, configobj\n","  Building wheel for citrination-client (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for citrination-client: filename=citrination_client-6.5.1-py2.py3-none-any.whl size=116097 sha256=b2ccad4d32fe4b02f43b3f1f45856f03f64fb681b6b674e7838fcffd5f02ebf1\n","  Stored in directory: /root/.cache/pip/wheels/6c/88/f5/5a3d5759228aabc63cb3baf2d767369ac99d18f3a941d381e7\n","  Building wheel for matminer (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for matminer: filename=matminer-0.6.5-cp37-none-any.whl size=1189789 sha256=34e77bfb45101279bbffa44369f0b1e093fe7574b808594774e2bde0c9d15c1f\n","  Stored in directory: /root/.cache/pip/wheels/b9/d9/ca/b03a29a28fb675c253a5792995097c48c25b8d409ddac4e2c1\n","  Building wheel for pypif (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pypif: filename=pypif-2.1.2-py2.py3-none-any.whl size=29506 sha256=897ecea353cbe61b5897d7f5ad648ad1124ebe9d19e63637f7346e3245c6e7c0\n","  Stored in directory: /root/.cache/pip/wheels/0d/19/de/9d99bb147337e90a209a44c89e67b3aaadcac4f6f8d106c13d\n","  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for future: filename=future-0.18.2-cp37-none-any.whl size=491058 sha256=403cb483928f9f98d2bfacc35f56ec1861978aa23b3f40227ffbdb60fc5adbb4\n","  Stored in directory: /root/.cache/pip/wheels/8b/99/a0/81daf51dcd359a9377b110a8a886b3895921802d2fc1b2397e\n","  Building wheel for configobj (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for configobj: filename=configobj-5.0.6-cp37-none-any.whl size=34547 sha256=9592bd2ffbb860d14507251c1fe4d1d4ebe17016411e812564f906977f695259\n","  Stored in directory: /root/.cache/pip/wheels/f1/e4/16/4981ca97c2d65106b49861e0b35e2660695be7219a2d351ee0\n","Successfully built citrination-client matminer pypif future configobj\n","\u001b[31mERROR: nbclient 0.5.3 has requirement jupyter-client>=6.1.5, but you'll have jupyter-client 5.3.5 which is incompatible.\u001b[0m\n","\u001b[31mERROR: dlhub-sdk 0.9.4 has requirement requests>=2.24.0, but you'll have requests 2.23.0 which is incompatible.\u001b[0m\n","\u001b[31mERROR: pymatgen 2022.0.5 has requirement numpy>=1.20.1, but you'll have numpy 1.19.5 which is incompatible.\u001b[0m\n","\u001b[31mERROR: pymatgen 2022.0.5 has requirement scipy>=1.5.0, but you'll have scipy 1.4.1 which is incompatible.\u001b[0m\n","\u001b[31mERROR: matminer 0.6.5 has requirement scikit-learn>=0.23.1, but you'll have scikit-learn 0.22.2.post1 which is incompatible.\u001b[0m\n","Installing collected packages: pypif, pyyaml, citrination-client, jsonschema, configobj, texttable, cryptography, pyjwt, globus-sdk, fair-research-login, bcrypt, pynacl, paramiko, typeguard, psutil, parsl, lockfile, python-daemon, typer, funcx, globus-nexus-client, mdf-toolbox, dlhub-sdk, future, uncertainties, plotly, ruamel.yaml.clib, ruamel.yaml, spglib, monty, pymatgen, tqdm, pint, matminer, mdf-forge, pyaml, scikit-optimize, sphinx-automodapi\n","  Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","  Found existing installation: jsonschema 2.6.0\n","    Uninstalling jsonschema-2.6.0:\n","      Successfully uninstalled jsonschema-2.6.0\n","  Found existing installation: typeguard 2.7.1\n","    Uninstalling typeguard-2.7.1:\n","      Successfully uninstalled typeguard-2.7.1\n","  Found existing installation: psutil 5.4.8\n","    Uninstalling psutil-5.4.8:\n","      Successfully uninstalled psutil-5.4.8\n","  Found existing installation: future 0.16.0\n","    Uninstalling future-0.16.0:\n","      Successfully uninstalled future-0.16.0\n","  Found existing installation: plotly 4.4.1\n","    Uninstalling plotly-4.4.1:\n","      Successfully uninstalled plotly-4.4.1\n","  Found existing installation: tqdm 4.41.1\n","    Uninstalling tqdm-4.41.1:\n","      Successfully uninstalled tqdm-4.41.1\n","Successfully installed bcrypt-3.2.0 citrination-client-6.5.1 configobj-5.0.6 cryptography-3.4.7 dlhub-sdk-0.9.4 fair-research-login-0.2.0 funcx-0.2.0 future-0.18.2 globus-nexus-client-0.3.0 globus-sdk-2.0.1 jsonschema-3.2.0 lockfile-0.12.2 matminer-0.6.5 mdf-forge-0.7.6 mdf-toolbox-0.5.7 monty-2021.3.3 paramiko-2.7.2 parsl-1.1.0a1 pint-0.17 plotly-4.14.3 psutil-5.8.0 pyaml-20.4.0 pyjwt-1.7.1 pymatgen-2022.0.5 pynacl-1.4.0 pypif-2.1.2 python-daemon-2.3.0 pyyaml-5.4.1 ruamel.yaml-0.17.4 ruamel.yaml.clib-0.2.2 scikit-optimize-0.8.1 spglib-1.16.1 sphinx-automodapi-0.13 texttable-1.6.3 tqdm-4.60.0 typeguard-2.12.0 typer-0.3.2 uncertainties-3.1.5\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["psutil"]}}},"metadata":{"tags":[]}},{"output_type":"stream","text":["Collecting pymatgen==2020.12.31\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e1/18/274b40cff34257a728071199d21105ced3116b42dd60793113eee7b1b5ca/pymatgen-2020.12.31.tar.gz (2.8MB)\n","\u001b[K     |████████████████████████████████| 2.8MB 13.3MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.14.3 in /usr/local/lib/python3.7/dist-packages (from pymatgen==2020.12.31) (1.19.5)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pymatgen==2020.12.31) (2.23.0)\n","Requirement already satisfied: ruamel.yaml>=0.15.6 in /usr/local/lib/python3.7/dist-packages (from pymatgen==2020.12.31) (0.17.4)\n","Requirement already satisfied: monty>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from pymatgen==2020.12.31) (2021.3.3)\n","Collecting scipy>=1.5.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/91/ee427c42957f8c4cbe477bf4f8b7f608e003a17941e509d1777e58648cb3/scipy-1.6.2-cp37-cp37m-manylinux1_x86_64.whl (27.4MB)\n","\u001b[K     |████████████████████████████████| 27.4MB 163kB/s \n","\u001b[?25hRequirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from pymatgen==2020.12.31) (0.8.9)\n","Requirement already satisfied: spglib>=1.9.9.44 in /usr/local/lib/python3.7/dist-packages (from pymatgen==2020.12.31) (1.16.1)\n","Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.7/dist-packages (from pymatgen==2020.12.31) (2.5)\n","Requirement already satisfied: matplotlib>=1.5 in /usr/local/lib/python3.7/dist-packages (from pymatgen==2020.12.31) (3.2.2)\n","Requirement already satisfied: palettable>=3.1.1 in /usr/local/lib/python3.7/dist-packages (from pymatgen==2020.12.31) (3.3.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.7/dist-packages (from pymatgen==2020.12.31) (1.7.1)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from pymatgen==2020.12.31) (1.1.5)\n","Requirement already satisfied: plotly>=4.5.0 in /usr/local/lib/python3.7/dist-packages (from pymatgen==2020.12.31) (4.14.3)\n","Requirement already satisfied: uncertainties>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from pymatgen==2020.12.31) (3.1.5)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pymatgen==2020.12.31) (2020.12.5)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pymatgen==2020.12.31) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pymatgen==2020.12.31) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->pymatgen==2020.12.31) (1.24.3)\n","Requirement already satisfied: ruamel.yaml.clib>=0.1.2; platform_python_implementation == \"CPython\" and python_version < \"3.10\" in /usr/local/lib/python3.7/dist-packages (from ruamel.yaml>=0.15.6->pymatgen==2020.12.31) (0.2.2)\n","Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from networkx>=2.2->pymatgen==2020.12.31) (4.4.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.5->pymatgen==2020.12.31) (0.10.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.5->pymatgen==2020.12.31) (1.3.1)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.5->pymatgen==2020.12.31) (2.8.1)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.5->pymatgen==2020.12.31) (2.4.7)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.7/dist-packages (from sympy->pymatgen==2020.12.31) (1.2.1)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->pymatgen==2020.12.31) (2018.9)\n","Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.7/dist-packages (from plotly>=4.5.0->pymatgen==2020.12.31) (1.3.3)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from plotly>=4.5.0->pymatgen==2020.12.31) (1.15.0)\n","Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from uncertainties>=3.1.4->pymatgen==2020.12.31) (0.18.2)\n","Building wheels for collected packages: pymatgen\n","  Building wheel for pymatgen (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pymatgen: filename=pymatgen-2020.12.31-cp37-cp37m-linux_x86_64.whl size=3590894 sha256=3b301a056c466c7a808b9861f72ec6277e8c22c80dbffb3963a75424bab7bbb2\n","  Stored in directory: /root/.cache/pip/wheels/bd/fd/4c/bbea735ca0989c51e67a45d1384b1ce3481bc2aa1337b4a6e9\n","Successfully built pymatgen\n","\u001b[31mERROR: matminer 0.6.5 has requirement scikit-learn>=0.23.1, but you'll have scikit-learn 0.22.2.post1 which is incompatible.\u001b[0m\n","\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n","Installing collected packages: scipy, pymatgen\n","  Found existing installation: scipy 1.4.1\n","    Uninstalling scipy-1.4.1:\n","      Successfully uninstalled scipy-1.4.1\n","  Found existing installation: pymatgen 2022.0.5\n","    Uninstalling pymatgen-2022.0.5:\n","      Successfully uninstalled pymatgen-2022.0.5\n","Successfully installed pymatgen-2020.12.31 scipy-1.6.2\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"I93RLdVb5kl3"},"source":["Now we'll sync Colab with our google drive so that we can save directly our outputs to google drive. If you haven't already I recommend making a folder in google drive titled \"MASTML_colab\" or something similar to direct all your results towards. Going forward I'll assume this folder exists and I'll base the runs out of that folder. If you want to change the naming that can work as well as long as you update when that location is referenced."]},{"cell_type":"code","metadata":{"id":"w-jHgEAFquSh","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618306178902,"user_tz":-330,"elapsed":22065,"user":{"displayName":"AGAM GOYAL","photoUrl":"","userId":"12333294385015277225"}},"outputId":"bed135fa-e85c-4870-9bff-ad757edb3a82"},"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"_PbyGFIU6B7Q"},"source":["We need to add the MAST-ML folder to our sys path so that python can find the modules\n"]},{"cell_type":"code","metadata":{"id":"nwQO48j1ws3S","executionInfo":{"status":"ok","timestamp":1618306181932,"user_tz":-330,"elapsed":1017,"user":{"displayName":"AGAM GOYAL","photoUrl":"","userId":"12333294385015277225"}}},"source":["import sys\n","sys.path.append('MAST-ML')"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Oe2e3F-x6EZz"},"source":["Here we import the MAST-ML modules used. Note that if you're making edits you may have to come back to update these imports to grab new functionality that isn't included here."]},{"cell_type":"code","metadata":{"id":"x8GIei1qQoWL","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618306193949,"user_tz":-330,"elapsed":9168,"user":{"displayName":"AGAM GOYAL","photoUrl":"","userId":"12333294385015277225"}},"outputId":"e76386e1-7b82-4d4e-bf62-098379508fb4"},"source":["\n","from mastml.mastml import Mastml\n","from mastml.datasets import LocalDatasets, DataCleaning\n","from mastml.preprocessing import SklearnPreprocessor\n","from mastml.models import SklearnModel\n","from mastml.data_splitters import SklearnDataSplitter, NoSplit\n","from mastml.feature_selectors import EnsembleModelFeatureSelector, NoSelect\n","from mastml.feature_generators import ElementalFeatureGenerator\n","from mastml.hyper_opt import GridSearch"],"execution_count":3,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/distributed/config.py:20: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n","  defaults = yaml.load(f)\n"],"name":"stderr"},{"output_type":"stream","text":["To install latest forestci compatabilty with scikit-learn>=0.24, run pip install git+git://github.com/scikit-learn-contrib/forest-confidence-interval.git\n","To import data from figshare, manually install figshare via git clone of git clone https://github.com/cognoma/figshare.git\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"oyt61i7J6kmc"},"source":["And finally we'll import pandas to help with handling dataframes throughout the notebook."]},{"cell_type":"code","metadata":{"id":"QasqdefdEh7n","executionInfo":{"status":"ok","timestamp":1618306208319,"user_tz":-330,"elapsed":1045,"user":{"displayName":"AGAM GOYAL","photoUrl":"","userId":"12333294385015277225"}}},"source":["import pandas as pd"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"P7s6xyjq6zxv"},"source":["## Section 2: Data Cleaning\n","\n","\n","---\n","this section is largely the same as the previous notebook in functionality.\n","We'll read in the same initial bandgap data we used in the previous notebook then perform the same cleaning steps:  \n","1) Filtering for \"Reliability\"  \n","2) Averaging bandgap values where we have duplicates  \n"]},{"cell_type":"markdown","metadata":{"id":"AkmW1QuL8ci9"},"source":["Read in the band gap data from our dataset. If you haven't already upload the bandgap_data_v2.csv data to the MASTML_colab folder"]},{"cell_type":"code","metadata":{"id":"185olJA6EWgH","executionInfo":{"status":"ok","timestamp":1618306394315,"user_tz":-330,"elapsed":2380,"user":{"displayName":"AGAM GOYAL","photoUrl":"","userId":"12333294385015277225"}}},"source":["mastml_df = pd.read_csv(\"./drive/MyDrive/MASTML_colab/bandgap_data_v2.csv\")"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PDkWyHHx8pSr"},"source":["Filter for only Reliability 1"]},{"cell_type":"code","metadata":{"id":"G2STcYIzFl31","executionInfo":{"status":"ok","timestamp":1618306398982,"user_tz":-330,"elapsed":1385,"user":{"displayName":"AGAM GOYAL","photoUrl":"","userId":"12333294385015277225"}}},"source":["mastml_df_filtered = mastml_df[mastml_df[\"Reliability\"]==1]"],"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DE8ygBOx8tr-"},"source":["Define the averaging function used previously in the nanohub notebook. Note that this wasn't explicitly in the previous notebook as it was being imported from a seperate script file with some of these helpep functions. but here we'll just define it locally in the notebook"]},{"cell_type":"code","metadata":{"id":"x9eHbyxRFrt8","executionInfo":{"status":"ok","timestamp":1618306404528,"user_tz":-330,"elapsed":1230,"user":{"displayName":"AGAM GOYAL","photoUrl":"","userId":"12333294385015277225"}}},"source":["def average_bandgaps(master_df, input_col_header, output_col_header):\n","    for chem_formula in master_df[input_col_header].unique():\n","        temp_df = master_df[master_df[input_col_header]==chem_formula].copy()\n","        if len(temp_df) > 1:\n","            avg_bandgap = temp_df[output_col_header].mean()\n","            indexes = temp_df.index\n","            master_df.at[indexes,output_col_header] = avg_bandgap\n","    master_df_clean = master_df.drop_duplicates(subset=input_col_header)\n","    return master_df_clean"],"execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pinx2EEU88jt"},"source":["We then call the function to do the same bandgap averaging when we have duplicates in the dataset."]},{"cell_type":"code","metadata":{"id":"dVywI4h5GpCF","executionInfo":{"status":"ok","timestamp":1618306407194,"user_tz":-330,"elapsed":1210,"user":{"displayName":"AGAM GOYAL","photoUrl":"","userId":"12333294385015277225"}}},"source":["mastml_df_clean = average_bandgaps(mastml_df_filtered, 'chemicalFormula Clean', 'Band gap values Clean')"],"execution_count":9,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2QtQtIOd9Cpd"},"source":["This section is new. We reset the index to match the previous notebook so that we can explicitly define the same Train / Test split that we used before. The test_indices object is just a hard copied list of the index values from the previous notebook. If you want to go check them you can find the X_test object and call X_test.index to see these yourself."]},{"cell_type":"code","metadata":{"id":"7kaM8janNfaH","executionInfo":{"status":"ok","timestamp":1618306409897,"user_tz":-330,"elapsed":1267,"user":{"displayName":"AGAM GOYAL","photoUrl":"","userId":"12333294385015277225"}}},"source":["mastml_df_clean.reset_index(inplace=True)\n","mastml_df_clean.drop(columns='level_0',inplace=True)"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"nDVtUAEyP7KO","executionInfo":{"status":"ok","timestamp":1618306412270,"user_tz":-330,"elapsed":1119,"user":{"displayName":"AGAM GOYAL","photoUrl":"","userId":"12333294385015277225"}}},"source":["test_indices = [279, 168, 192,  33, 223,  22, 341, 453, 460, 455, 120, 430, 436,\n","            366, 292, 278, 163, 216, 420, 210, 214, 422, 340,  41, 416, 146,\n","            280, 229, 300, 111, 407, 250, 379,  20, 356,   4, 141, 139, 121,\n","            324, 147, 415,  57, 301, 393, 454,  30]"],"execution_count":11,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IQWI9X0A9e9D"},"source":["Finally we define a new column \"testdata\" which is going to be a binary column that is either 0 for \"not testing data\" or 1 for \"is testing data\". This is what we can feed into MAST-ML to explicitly define a set of Test data that is held out from all training."]},{"cell_type":"code","metadata":{"id":"Q4FJiTWAQt_K","executionInfo":{"status":"ok","timestamp":1618306416501,"user_tz":-330,"elapsed":1001,"user":{"displayName":"AGAM GOYAL","photoUrl":"","userId":"12333294385015277225"}}},"source":["mastml_df_clean[\"testdata\"]=0"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"crO7RhFwQcJf","executionInfo":{"status":"ok","timestamp":1618306420406,"user_tz":-330,"elapsed":1460,"user":{"displayName":"AGAM GOYAL","photoUrl":"","userId":"12333294385015277225"}}},"source":["for idx in test_indices:\n","  mastml_df_clean.at[idx,'testdata']=1"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"S4wpDg0zJAQN","executionInfo":{"status":"ok","timestamp":1618306423475,"user_tz":-330,"elapsed":1010,"user":{"displayName":"AGAM GOYAL","photoUrl":"","userId":"12333294385015277225"}}},"source":["output_path = \"./drive/MyDrive/MASTML_colab/bandgap_data_v3.csv\"\n","mastml_df_clean.to_csv(output_path,index=False)"],"execution_count":14,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AEQqAql19ybB"},"source":["Notice how in the initial data cleaning and configuration there is still a bit that we do outside of MAST-ML. While MAST-ML gives a good deal of flexibility and useful tools for performing these machine learning workflows there will often still be custom steps like this that get added to the overall workflow that varies dataset by dataset."]},{"cell_type":"markdown","metadata":{"id":"fcWk1k177SWM"},"source":["## Section 3: Initializing MAST-ML\n","---\n","Now we'll dive into interacting more directly with the MAST-ML software. The first thing we need to do is setup some of the baseline information that MASTML will use as we call different sections of the code. This is similar to the [general] section from the previous configuration file oriented code base.\n"]},{"cell_type":"markdown","metadata":{"id":"dsRqGRLs_IXU"},"source":["Set the name of the savepath to save MAST-ML results to. It's recommended to make this a unique name each time you come back to this notebook. That way all the outputs you get from each session will be in a unique location that's easier to come back to later.\n","\n","By default I've set the output to the \"hyperopt\" folder under our colab folder."]},{"cell_type":"code","metadata":{"id":"Xf8MFHjlM7Oe","executionInfo":{"status":"ok","timestamp":1618306475367,"user_tz":-330,"elapsed":1482,"user":{"displayName":"AGAM GOYAL","photoUrl":"","userId":"12333294385015277225"}}},"source":["SAVEPATH = 'drive/MyDrive/MASTML_colab/hyperopt'\n","\n","mastml = Mastml(savepath=SAVEPATH)\n","savepath = mastml.get_savepath"],"execution_count":15,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"I359kFP2_wpk"},"source":["With MAST-ML initialized you should see your output directory created. You can check this using the file tree on the left of the screen or directly through google drive.\n","\n","Next up we need to define the configuration of our Data file that we setup earlier. We'll define the names for all of the key components:  \n","target: the target variable that we want to predict  \n","extra_columns: the metadata columns that aren't features but we still want to keep track off  \n","testdata_columns: the column with binary values defining what is and isn't test data  \n","group_column: column names specifying unique groups in the data. We don't use this during this workflow  \n","as_frame: determines the structure of outputs. True gives up dataframe outputs that are easier to read in the notebook"]},{"cell_type":"code","metadata":{"id":"kWxrG-RgxeTA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618306486712,"user_tz":-330,"elapsed":1034,"user":{"displayName":"AGAM GOYAL","photoUrl":"","userId":"12333294385015277225"}},"outputId":"f76c830c-a13c-412a-e394-faf4520fb955"},"source":["target = 'Band gap values Clean'\n","extra_columns = ['index', 'Band gap units', 'Band gap method', 'Reliability','chemicalFormula Clean']\n","testdata_columns = ['testdata']\n","\n","# calling the LocalDatasets section of the code initializes this section which we then execute with the method below\n","d = LocalDatasets(file_path='./drive/MyDrive/MASTML_colab/bandgap_data_v3.csv', \n","                  target=target, \n","                  extra_columns=extra_columns, \n","                  group_column=None,\n","                  testdata_columns=testdata_columns,\n","                  as_frame=True)\n","\n","# Load the data with the load_data() method\n","data_dict = d.load_data()"],"execution_count":16,"outputs":[{"output_type":"stream","text":["WARNING: feature_names not specified but target was specified. Assuming all columns except target and extra columns are features\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"S07AJOwqBZbc"},"source":["Let's take a second to look through what just happened. In the previous cell the \"data_dict\" object was defined. It is a dictionary of various things that were loaded in from the dataseet. We'll pull those out of the dictionary to set them all to unique objects."]},{"cell_type":"markdown","metadata":{"id":"XT7AuA-mBuh9"},"source":["We see there are 5 keys:  \n","  X: the X feature matrix (used to fit the ML model). notice this is empty becausee we haven't done any feature generation  \n","  y: the y target data vector (true values)  \n","  X_extra: matrix of meta data not used in fitting (i.e. not part of X or y)  \n","  groups: vector of group labels. empty because we didn't set it  \n","  X_testdata: matrix or vector of left out data indices"]},{"cell_type":"code","metadata":{"id":"Nrx-OGW3_dap","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618306496565,"user_tz":-330,"elapsed":2018,"user":{"displayName":"AGAM GOYAL","photoUrl":"","userId":"12333294385015277225"}},"outputId":"5c140348-6cd7-4c41-c524-bcfebd2ed75d"},"source":["data_dict.keys()"],"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["dict_keys(['X', 'y', 'groups', 'X_extra', 'X_testdata'])"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"code","metadata":{"id":"a-Lrm2lG_7hi","executionInfo":{"status":"ok","timestamp":1618306498387,"user_tz":-330,"elapsed":677,"user":{"displayName":"AGAM GOYAL","photoUrl":"","userId":"12333294385015277225"}}},"source":["X = data_dict['X']\n","y = data_dict['y']\n","X_extra = data_dict['X_extra']\n","groups = data_dict['groups']\n","X_testdata = data_dict['X_testdata']"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"pR-pTG-Zx-AW","colab":{"base_uri":"https://localhost:8080/","height":376},"executionInfo":{"status":"ok","timestamp":1618306502131,"user_tz":-330,"elapsed":1373,"user":{"displayName":"AGAM GOYAL","photoUrl":"","userId":"12333294385015277225"}},"outputId":"5838378b-7d74-4633-dcf4-f3cd4d285c6e"},"source":["X"],"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","    </tr>\n","    <tr>\n","      <th>462</th>\n","    </tr>\n","    <tr>\n","      <th>463</th>\n","    </tr>\n","    <tr>\n","      <th>464</th>\n","    </tr>\n","    <tr>\n","      <th>465</th>\n","    </tr>\n","    <tr>\n","      <th>466</th>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>467 rows × 0 columns</p>\n","</div>"],"text/plain":["Empty DataFrame\n","Columns: []\n","Index: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, ...]\n","\n","[467 rows x 0 columns]"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"code","metadata":{"id":"DDRPN14syAue","executionInfo":{"status":"ok","timestamp":1618306505372,"user_tz":-330,"elapsed":1024,"user":{"displayName":"AGAM GOYAL","photoUrl":"","userId":"12333294385015277225"}}},"source":["groups"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"VuKB49u_yM9c","colab":{"base_uri":"https://localhost:8080/","height":391},"executionInfo":{"status":"ok","timestamp":1618306513639,"user_tz":-330,"elapsed":6944,"user":{"displayName":"AGAM GOYAL","photoUrl":"","userId":"12333294385015277225"}},"outputId":"df22a642-80ee-4f5b-d9f1-ec9286a90393"},"source":["X_extra"],"execution_count":21,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>index</th>\n","      <th>Band gap units</th>\n","      <th>Band gap method</th>\n","      <th>Reliability</th>\n","      <th>chemicalFormula Clean</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>eV</td>\n","      <td>Reflection</td>\n","      <td>1</td>\n","      <td>Li1F1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>6</td>\n","      <td>eV</td>\n","      <td>Reflection</td>\n","      <td>1</td>\n","      <td>Li1Cl1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>7</td>\n","      <td>eV</td>\n","      <td>Absorption</td>\n","      <td>1</td>\n","      <td>Li1Br1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>9</td>\n","      <td>eV</td>\n","      <td>Thermal activation</td>\n","      <td>1</td>\n","      <td>Li3Sb1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>10</td>\n","      <td>eV</td>\n","      <td>Reflection</td>\n","      <td>1</td>\n","      <td>Li1I1</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>462</th>\n","      <td>1437</td>\n","      <td>eV</td>\n","      <td>Absorption</td>\n","      <td>1</td>\n","      <td>Bi1I3</td>\n","    </tr>\n","    <tr>\n","      <th>463</th>\n","      <td>1445</td>\n","      <td>eV</td>\n","      <td>Magnetoreflection</td>\n","      <td>1</td>\n","      <td>Bi</td>\n","    </tr>\n","    <tr>\n","      <th>464</th>\n","      <td>1448</td>\n","      <td>eV</td>\n","      <td>NaN</td>\n","      <td>1</td>\n","      <td>Th1O2</td>\n","    </tr>\n","    <tr>\n","      <th>465</th>\n","      <td>1455</td>\n","      <td>eV</td>\n","      <td>Thermal activation</td>\n","      <td>1</td>\n","      <td>UO</td>\n","    </tr>\n","    <tr>\n","      <th>466</th>\n","      <td>1456</td>\n","      <td>eV</td>\n","      <td>Absorption</td>\n","      <td>1</td>\n","      <td>U1O2</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>467 rows × 5 columns</p>\n","</div>"],"text/plain":["     index Band gap units  ... Reliability  chemicalFormula Clean\n","0        0             eV  ...           1                  Li1F1\n","1        6             eV  ...           1                 Li1Cl1\n","2        7             eV  ...           1                 Li1Br1\n","3        9             eV  ...           1                 Li3Sb1\n","4       10             eV  ...           1                  Li1I1\n","..     ...            ...  ...         ...                    ...\n","462   1437             eV  ...           1                  Bi1I3\n","463   1445             eV  ...           1                     Bi\n","464   1448             eV  ...           1                  Th1O2\n","465   1455             eV  ...           1                     UO\n","466   1456             eV  ...           1                   U1O2\n","\n","[467 rows x 5 columns]"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"code","metadata":{"id":"_jdQjcY5yN6z","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618306517812,"user_tz":-330,"elapsed":1495,"user":{"displayName":"AGAM GOYAL","photoUrl":"","userId":"12333294385015277225"}},"outputId":"6ebf7d93-a1f4-4121-89fd-d5e1117385a0"},"source":["X_testdata"],"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[array([  4,  20,  22,  30,  33,  41,  57, 111, 120, 121, 139, 141, 146,\n","        147, 163, 168, 192, 210, 214, 216, 223, 229, 250, 278, 279, 280,\n","        292, 300, 301, 324, 340, 341, 356, 366, 379, 393, 407, 415, 416,\n","        420, 422, 430, 436, 453, 454, 455, 460])]"]},"metadata":{"tags":[]},"execution_count":22}]},{"cell_type":"markdown","metadata":{"id":"Wg9RjtoaEP9Z"},"source":["## Section 4: Feature Generation/Engineering\n","---\n","Now we'll setup the input features for the model with a few mastml runs \n"]},{"cell_type":"markdown","metadata":{"id":"Jj5kqXFTCHXl"},"source":["If the data contains missing values (this one doesn't), we can clean the data with the built in tools in MAST-ML, which corrects missing values and provides some basic analysis of the input data. Since there are no missing values the data cleaner will still output some useful plots and statistics of our input data."]},{"cell_type":"code","metadata":{"id":"YgQJg2fDyQRU","executionInfo":{"status":"ok","timestamp":1618306523310,"user_tz":-330,"elapsed":3190,"user":{"displayName":"AGAM GOYAL","photoUrl":"","userId":"12333294385015277225"}}},"source":["cleaner = DataCleaning()\n","X, y = cleaner.evaluate(X=X, \n","                        y=y, \n","                        method='imputation', \n","                        strategy='mean', \n","                        savepath=savepath)"],"execution_count":23,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IzuXHap6CYgy"},"source":["Looking at the format of the DataCleaning section also highlights the key way we will interact with MAST-ML in this format. For each section of the code we want to use we'll initialize it using what's called a class name, in this case \"DataCleaning\", and then call the \"evaluate\" method to essentially run the code for that Class.\n","\n","Let's look through the outputs and compare them to some of the initial dataset analysis and compare to the previous Nanohub workflow. Open the \"histogram_target_values.png\" file in the newly created DataCleaning folder under our output directory. Compare back to the histogram we made in the previous notebook. Are they the same?\n","\n","This is the type of check we would do to make sure we aren't missing any data switching between the two platforms."]},{"cell_type":"markdown","metadata":{"id":"O0cJ9kJAFMyd"},"source":["Next is generating the elemental features used in the model. Just like the previous step we define the class of feature generation we want to use, and then call the evaluate method. Again results are output to a new folder with the name of the Class that was evaluated. The features are also added to the X object so we can continue to use them directly without having to read in from the generated files.\n","\n","You can see from the output that MAST-ML is also performing some basic feature engineering by dropping features that are missing values. This is the most basic way of handling missing values, and if we wanted to do something more complex later we could come back and use imputation to fill in those missing values instead."]},{"cell_type":"code","metadata":{"id":"4Si2f98-cY6u","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618306537722,"user_tz":-330,"elapsed":11481,"user":{"displayName":"AGAM GOYAL","photoUrl":"","userId":"12333294385015277225"}},"outputId":"50bb3d6a-27ef-4a9d-ad32-23a4a7c5afd4"},"source":["generator = ElementalFeatureGenerator(composition_df = X_extra[\"chemicalFormula Clean\"],\n","                      feature_types='composition_avg',\n","                      remove_constant_columns=True)\n","X, y = generator.evaluate(X = X,\n","                          y = y,\n","                          savepath = savepath)"],"execution_count":24,"outputs":[{"output_type":"stream","text":["Dropping 1/88 generated columns due to missing values\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"4vvs0Gd6GEnu"},"source":["Using the cell block below with outputs the feature object directly compare the features generated to those in the previous workflow. Do we have the same total number?\n","\n","If they're different can you think of any reasons why?  \n","hint: mastml does some initial cleaning automatically on the features."]},{"cell_type":"code","metadata":{"id":"8LrJ6AX7hrpM","colab":{"base_uri":"https://localhost:8080/","height":411},"executionInfo":{"status":"ok","timestamp":1618306543045,"user_tz":-330,"elapsed":1024,"user":{"displayName":"AGAM GOYAL","photoUrl":"","userId":"12333294385015277225"}},"outputId":"1bbec902-e223-481a-885d-0b3de7e402c1"},"source":["X"],"execution_count":25,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>AtomicNumber_composition_average</th>\n","      <th>AtomicRadii_composition_average</th>\n","      <th>AtomicVolume_composition_average</th>\n","      <th>AtomicWeight_composition_average</th>\n","      <th>BCCefflatcnt_composition_average</th>\n","      <th>BCCenergy_pa_composition_average</th>\n","      <th>BCCfermi_composition_average</th>\n","      <th>BCCmagmom_composition_average</th>\n","      <th>BCCvolume_pa_composition_average</th>\n","      <th>BCCvolume_padiff_composition_average</th>\n","      <th>BoilingT_composition_average</th>\n","      <th>BulkModulus_composition_average</th>\n","      <th>Column_composition_average</th>\n","      <th>CovalentRadii_composition_average</th>\n","      <th>CovalentRadius_composition_average</th>\n","      <th>Density_composition_average</th>\n","      <th>ElasticModulus_composition_average</th>\n","      <th>ElectricalConductivity_composition_average</th>\n","      <th>ElectronAffinity_composition_average</th>\n","      <th>Electronegativity_composition_average</th>\n","      <th>FirstIonizationEnergy_composition_average</th>\n","      <th>GSbandgap_composition_average</th>\n","      <th>GSenergy_pa_composition_average</th>\n","      <th>GSestBCClatcnt_composition_average</th>\n","      <th>GSestFCClatcnt_composition_average</th>\n","      <th>GSmagmom_composition_average</th>\n","      <th>GSvolume_pa_composition_average</th>\n","      <th>Group_composition_average</th>\n","      <th>HHIp_composition_average</th>\n","      <th>HHIr_composition_average</th>\n","      <th>HeatCapacityMass_composition_average</th>\n","      <th>HeatCapacityMolar_composition_average</th>\n","      <th>HeatFusion_composition_average</th>\n","      <th>HeatVaporization_composition_average</th>\n","      <th>ICSDVolume_composition_average</th>\n","      <th>IonicRadii_composition_average</th>\n","      <th>IonizationEnergy_composition_average</th>\n","      <th>IsAlkali_composition_average</th>\n","      <th>IsAlkalineEarth_composition_average</th>\n","      <th>IsBCC_composition_average</th>\n","      <th>...</th>\n","      <th>IsHalogen_composition_average</th>\n","      <th>IsHexagonal_composition_average</th>\n","      <th>IsMetal_composition_average</th>\n","      <th>IsMetalloid_composition_average</th>\n","      <th>IsMonoclinic_composition_average</th>\n","      <th>IsNonmetal_composition_average</th>\n","      <th>IsOrthorhombic_composition_average</th>\n","      <th>IsPnictide_composition_average</th>\n","      <th>IsRareEarth_composition_average</th>\n","      <th>IsRhombohedral_composition_average</th>\n","      <th>IsSimpleCubic_composition_average</th>\n","      <th>IsTetragonal_composition_average</th>\n","      <th>IsTransitionMetal_composition_average</th>\n","      <th>MeltingT_composition_average</th>\n","      <th>MendeleevNumber_composition_average</th>\n","      <th>MiracleRadius_composition_average</th>\n","      <th>NUnfilled_composition_average</th>\n","      <th>NValance_composition_average</th>\n","      <th>NdUnfilled_composition_average</th>\n","      <th>NdValence_composition_average</th>\n","      <th>NfUnfilled_composition_average</th>\n","      <th>NfValence_composition_average</th>\n","      <th>NpUnfilled_composition_average</th>\n","      <th>NpValence_composition_average</th>\n","      <th>NsUnfilled_composition_average</th>\n","      <th>NsValence_composition_average</th>\n","      <th>Number_composition_average</th>\n","      <th>Period_composition_average</th>\n","      <th>Polarizability_composition_average</th>\n","      <th>Row_composition_average</th>\n","      <th>SecondIonizationEnergy_composition_average</th>\n","      <th>ShearModulus_composition_average</th>\n","      <th>SpaceGroupNumber_composition_average</th>\n","      <th>SpecificHeatCapacity_composition_average</th>\n","      <th>ThermalConductivity_composition_average</th>\n","      <th>ThermalExpansionCoefficient_composition_average</th>\n","      <th>ThirdIonizationEnergy_composition_average</th>\n","      <th>n_ws^third_composition_average</th>\n","      <th>phi_composition_average</th>\n","      <th>valence_composition_average</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>6.000000</td>\n","      <td>1.135000</td>\n","      <td>9311.576313</td>\n","      <td>12.969702</td>\n","      <td>5.772386</td>\n","      <td>-1.346741</td>\n","      <td>-0.679877</td>\n","      <td>0.0</td>\n","      <td>12.4700</td>\n","      <td>-0.680417</td>\n","      <td>849.940000</td>\n","      <td>5.500000</td>\n","      <td>9.000000</td>\n","      <td>0.975000</td>\n","      <td>92.500000</td>\n","      <td>268.348000</td>\n","      <td>5.000000</td>\n","      <td>5.850000</td>\n","      <td>193.900000</td>\n","      <td>2.480000</td>\n","      <td>11.407259</td>\n","      <td>0.9850</td>\n","      <td>-1.783974</td>\n","      <td>2.950630</td>\n","      <td>3.717561</td>\n","      <td>0.0</td>\n","      <td>13.150417</td>\n","      <td>9.000000</td>\n","      <td>2200.000000</td>\n","      <td>2850.000000</td>\n","      <td>2.203000</td>\n","      <td>28.0820</td>\n","      <td>1.627500</td>\n","      <td>75.184900</td>\n","      <td>19.000000</td>\n","      <td>1.045000</td>\n","      <td>1100.500</td>\n","      <td>0.50</td>\n","      <td>0.0</td>\n","      <td>0.50</td>\n","      <td>...</td>\n","      <td>0.50</td>\n","      <td>0.0</td>\n","      <td>0.500000</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","      <td>0.500000</td>\n","      <td>0.000000</td>\n","      <td>0.00</td>\n","      <td>0.000000</td>\n","      <td>0.00</td>\n","      <td>0.500000</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>253.595000</td>\n","      <td>47.000000</td>\n","      <td>76.000000</td>\n","      <td>1.0</td>\n","      <td>4.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.500000</td>\n","      <td>2.500000</td>\n","      <td>0.50</td>\n","      <td>1.50</td>\n","      <td>6.000000</td>\n","      <td>2.000000</td>\n","      <td>12.446000</td>\n","      <td>2.000000</td>\n","      <td>55.804000</td>\n","      <td>2.100000</td>\n","      <td>122.00</td>\n","      <td>2.203000</td>\n","      <td>42.363950</td>\n","      <td>923.000000</td>\n","      <td>92.579000</td>\n","      <td>0.490000</td>\n","      <td>1.4250</td>\n","      <td>1.000000</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>10.000000</td>\n","      <td>1.270000</td>\n","      <td>9169.525548</td>\n","      <td>21.197000</td>\n","      <td>6.658641</td>\n","      <td>-1.410040</td>\n","      <td>1.219961</td>\n","      <td>0.0</td>\n","      <td>18.5250</td>\n","      <td>-2.020417</td>\n","      <td>926.980000</td>\n","      <td>6.050000</td>\n","      <td>9.000000</td>\n","      <td>1.110000</td>\n","      <td>115.000000</td>\n","      <td>269.107000</td>\n","      <td>5.000000</td>\n","      <td>5.850000</td>\n","      <td>204.300000</td>\n","      <td>2.070000</td>\n","      <td>9.179675</td>\n","      <td>1.2465</td>\n","      <td>-1.827160</td>\n","      <td>3.436376</td>\n","      <td>4.329563</td>\n","      <td>0.0</td>\n","      <td>20.545417</td>\n","      <td>9.000000</td>\n","      <td>2200.000000</td>\n","      <td>2600.000000</td>\n","      <td>2.030500</td>\n","      <td>29.4045</td>\n","      <td>3.100000</td>\n","      <td>78.650000</td>\n","      <td>25.300000</td>\n","      <td>1.285000</td>\n","      <td>885.550</td>\n","      <td>0.50</td>\n","      <td>0.0</td>\n","      <td>0.50</td>\n","      <td>...</td>\n","      <td>0.50</td>\n","      <td>0.0</td>\n","      <td>0.500000</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","      <td>0.500000</td>\n","      <td>0.500000</td>\n","      <td>0.00</td>\n","      <td>0.000000</td>\n","      <td>0.00</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>312.645000</td>\n","      <td>47.500000</td>\n","      <td>76.000000</td>\n","      <td>1.0</td>\n","      <td>4.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.500000</td>\n","      <td>2.500000</td>\n","      <td>0.50</td>\n","      <td>1.50</td>\n","      <td>10.000000</td>\n","      <td>2.500000</td>\n","      <td>13.257500</td>\n","      <td>2.500000</td>\n","      <td>50.224000</td>\n","      <td>2.100000</td>\n","      <td>146.50</td>\n","      <td>2.031000</td>\n","      <td>42.354450</td>\n","      <td>23.000000</td>\n","      <td>81.031000</td>\n","      <td>0.490000</td>\n","      <td>1.4250</td>\n","      <td>4.000000</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>19.000000</td>\n","      <td>1.345000</td>\n","      <td>32.035942</td>\n","      <td>43.422500</td>\n","      <td>6.919518</td>\n","      <td>-1.432083</td>\n","      <td>1.117212</td>\n","      <td>0.0</td>\n","      <td>21.0350</td>\n","      <td>-2.001667</td>\n","      <td>973.500000</td>\n","      <td>6.450000</td>\n","      <td>9.000000</td>\n","      <td>1.185000</td>\n","      <td>124.000000</td>\n","      <td>1827.500000</td>\n","      <td>5.000000</td>\n","      <td>5.850000</td>\n","      <td>192.200000</td>\n","      <td>1.970000</td>\n","      <td>8.602760</td>\n","      <td>0.7285</td>\n","      <td>-1.726456</td>\n","      <td>3.552844</td>\n","      <td>4.476302</td>\n","      <td>0.0</td>\n","      <td>23.036667</td>\n","      <td>9.000000</td>\n","      <td>3100.000000</td>\n","      <td>5550.000000</td>\n","      <td>2.028000</td>\n","      <td>50.2750</td>\n","      <td>4.142500</td>\n","      <td>80.912500</td>\n","      <td>43.350000</td>\n","      <td>1.360000</td>\n","      <td>829.950</td>\n","      <td>0.50</td>\n","      <td>0.0</td>\n","      <td>0.50</td>\n","      <td>...</td>\n","      <td>0.50</td>\n","      <td>0.0</td>\n","      <td>0.500000</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","      <td>0.500000</td>\n","      <td>0.500000</td>\n","      <td>0.00</td>\n","      <td>0.000000</td>\n","      <td>0.00</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>359.745000</td>\n","      <td>48.000000</td>\n","      <td>76.000000</td>\n","      <td>1.0</td>\n","      <td>9.000000</td>\n","      <td>0.000000</td>\n","      <td>5.000000</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.500000</td>\n","      <td>2.500000</td>\n","      <td>0.50</td>\n","      <td>1.50</td>\n","      <td>19.000000</td>\n","      <td>3.000000</td>\n","      <td>13.692500</td>\n","      <td>3.000000</td>\n","      <td>49.219000</td>\n","      <td>2.100000</td>\n","      <td>146.50</td>\n","      <td>1.904000</td>\n","      <td>42.411000</td>\n","      <td>23.000000</td>\n","      <td>79.225500</td>\n","      <td>0.490000</td>\n","      <td>1.4250</td>\n","      <td>4.000000</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>15.000000</td>\n","      <td>1.560000</td>\n","      <td>23.705899</td>\n","      <td>35.645750</td>\n","      <td>6.704252</td>\n","      <td>-2.371630</td>\n","      <td>2.267697</td>\n","      <td>0.0</td>\n","      <td>19.1550</td>\n","      <td>-1.180000</td>\n","      <td>1676.250000</td>\n","      <td>18.750000</td>\n","      <td>4.500000</td>\n","      <td>1.272500</td>\n","      <td>130.750000</td>\n","      <td>2075.500000</td>\n","      <td>24.250000</td>\n","      <td>9.425000</td>\n","      <td>70.100000</td>\n","      <td>1.247500</td>\n","      <td>6.195887</td>\n","      <td>0.0000</td>\n","      <td>-2.431756</td>\n","      <td>3.405574</td>\n","      <td>4.290754</td>\n","      <td>0.0</td>\n","      <td>20.335000</td>\n","      <td>4.500000</td>\n","      <td>4150.000000</td>\n","      <td>4000.000000</td>\n","      <td>2.738250</td>\n","      <td>24.9525</td>\n","      <td>7.197500</td>\n","      <td>127.317500</td>\n","      <td>23.750000</td>\n","      <td>0.760000</td>\n","      <td>598.425</td>\n","      <td>0.75</td>\n","      <td>0.0</td>\n","      <td>0.75</td>\n","      <td>...</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","      <td>1.000000</td>\n","      <td>0.25</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.25</td>\n","      <td>0.000000</td>\n","      <td>0.25</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>566.212500</td>\n","      <td>22.000000</td>\n","      <td>152.750000</td>\n","      <td>1.5</td>\n","      <td>4.500000</td>\n","      <td>0.000000</td>\n","      <td>2.500000</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.750000</td>\n","      <td>0.750000</td>\n","      <td>0.75</td>\n","      <td>1.25</td>\n","      <td>15.000000</td>\n","      <td>2.750000</td>\n","      <td>19.901250</td>\n","      <td>2.750000</td>\n","      <td>61.611000</td>\n","      <td>8.150000</td>\n","      <td>213.25</td>\n","      <td>2.738250</td>\n","      <td>69.600000</td>\n","      <td>37.250000</td>\n","      <td>98.163250</td>\n","      <td>1.050000</td>\n","      <td>3.2375</td>\n","      <td>2.000000</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>28.000000</td>\n","      <td>1.440000</td>\n","      <td>32.101458</td>\n","      <td>66.922735</td>\n","      <td>7.343549</td>\n","      <td>-1.459519</td>\n","      <td>2.360221</td>\n","      <td>0.0</td>\n","      <td>25.9350</td>\n","      <td>-3.869167</td>\n","      <td>1036.150000</td>\n","      <td>9.350000</td>\n","      <td>9.000000</td>\n","      <td>1.280000</td>\n","      <td>133.500000</td>\n","      <td>2737.500000</td>\n","      <td>5.000000</td>\n","      <td>5.850000</td>\n","      <td>177.550000</td>\n","      <td>1.820000</td>\n","      <td>7.921489</td>\n","      <td>0.5310</td>\n","      <td>-1.687645</td>\n","      <td>3.814044</td>\n","      <td>4.805395</td>\n","      <td>0.0</td>\n","      <td>29.804167</td>\n","      <td>9.000000</td>\n","      <td>3900.000000</td>\n","      <td>4500.000000</td>\n","      <td>1.898000</td>\n","      <td>39.6450</td>\n","      <td>5.380000</td>\n","      <td>84.000000</td>\n","      <td>32.050000</td>\n","      <td>1.480000</td>\n","      <td>764.200</td>\n","      <td>0.50</td>\n","      <td>0.0</td>\n","      <td>0.50</td>\n","      <td>...</td>\n","      <td>0.50</td>\n","      <td>0.0</td>\n","      <td>0.500000</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","      <td>0.500000</td>\n","      <td>0.500000</td>\n","      <td>0.00</td>\n","      <td>0.000000</td>\n","      <td>0.00</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>420.270000</td>\n","      <td>48.500000</td>\n","      <td>76.000000</td>\n","      <td>1.0</td>\n","      <td>9.000000</td>\n","      <td>0.000000</td>\n","      <td>5.000000</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.500000</td>\n","      <td>2.500000</td>\n","      <td>0.50</td>\n","      <td>1.50</td>\n","      <td>28.000000</td>\n","      <td>3.500000</td>\n","      <td>14.680000</td>\n","      <td>3.500000</td>\n","      <td>47.884500</td>\n","      <td>2.100000</td>\n","      <td>146.50</td>\n","      <td>1.863500</td>\n","      <td>42.574500</td>\n","      <td>66.500000</td>\n","      <td>77.725500</td>\n","      <td>0.490000</td>\n","      <td>1.4250</td>\n","      <td>4.000000</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>462</th>\n","      <td>60.500000</td>\n","      <td>1.422500</td>\n","      <td>40.865008</td>\n","      <td>147.423452</td>\n","      <td>8.158525</td>\n","      <td>-1.763974</td>\n","      <td>5.485714</td>\n","      <td>0.0</td>\n","      <td>33.9975</td>\n","      <td>-6.501250</td>\n","      <td>802.225000</td>\n","      <td>13.525000</td>\n","      <td>16.500000</td>\n","      <td>1.362500</td>\n","      <td>141.250000</td>\n","      <td>6150.000000</td>\n","      <td>8.500000</td>\n","      <td>0.225000</td>\n","      <td>248.975000</td>\n","      <td>2.500000</td>\n","      <td>9.659820</td>\n","      <td>0.7965</td>\n","      <td>-2.122475</td>\n","      <td>4.320688</td>\n","      <td>5.443726</td>\n","      <td>0.0</td>\n","      <td>40.498750</td>\n","      <td>16.500000</td>\n","      <td>5000.000000</td>\n","      <td>5100.000000</td>\n","      <td>0.191000</td>\n","      <td>47.2025</td>\n","      <td>8.596500</td>\n","      <td>60.425000</td>\n","      <td>40.700000</td>\n","      <td>1.907500</td>\n","      <td>932.125</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","      <td>0.00</td>\n","      <td>...</td>\n","      <td>0.75</td>\n","      <td>0.0</td>\n","      <td>0.250000</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","      <td>0.750000</td>\n","      <td>0.750000</td>\n","      <td>0.25</td>\n","      <td>0.000000</td>\n","      <td>0.25</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>426.237500</td>\n","      <td>93.500000</td>\n","      <td>40.500000</td>\n","      <td>1.5</td>\n","      <td>20.000000</td>\n","      <td>0.000000</td>\n","      <td>10.000000</td>\n","      <td>0.000000</td>\n","      <td>3.5</td>\n","      <td>1.500000</td>\n","      <td>4.500000</td>\n","      <td>0.00</td>\n","      <td>2.00</td>\n","      <td>60.500000</td>\n","      <td>5.250000</td>\n","      <td>3.868750</td>\n","      <td>5.250000</td>\n","      <td>18.520000</td>\n","      <td>3.000000</td>\n","      <td>51.00</td>\n","      <td>0.139250</td>\n","      <td>2.304250</td>\n","      <td>68.600000</td>\n","      <td>31.139750</td>\n","      <td>0.290000</td>\n","      <td>1.0375</td>\n","      <td>6.500000</td>\n","    </tr>\n","    <tr>\n","      <th>463</th>\n","      <td>83.000000</td>\n","      <td>1.700000</td>\n","      <td>35.483459</td>\n","      <td>208.980400</td>\n","      <td>7.821898</td>\n","      <td>-3.895384</td>\n","      <td>8.463157</td>\n","      <td>0.0</td>\n","      <td>29.9100</td>\n","      <td>-3.040000</td>\n","      <td>1837.000000</td>\n","      <td>31.000000</td>\n","      <td>15.000000</td>\n","      <td>1.460000</td>\n","      <td>148.000000</td>\n","      <td>9780.000000</td>\n","      <td>34.000000</td>\n","      <td>0.900000</td>\n","      <td>110.000000</td>\n","      <td>2.020000</td>\n","      <td>7.285500</td>\n","      <td>0.0000</td>\n","      <td>-3.973694</td>\n","      <td>4.039198</td>\n","      <td>5.089071</td>\n","      <td>0.0</td>\n","      <td>32.950000</td>\n","      <td>15.000000</td>\n","      <td>5300.000000</td>\n","      <td>6000.000000</td>\n","      <td>0.122000</td>\n","      <td>25.5200</td>\n","      <td>11.106000</td>\n","      <td>179.000000</td>\n","      <td>35.300000</td>\n","      <td>1.030000</td>\n","      <td>703.300</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","      <td>0.00</td>\n","      <td>...</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","      <td>1.000000</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>1.00</td>\n","      <td>0.000000</td>\n","      <td>1.00</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>544.400000</td>\n","      <td>86.000000</td>\n","      <td>162.000000</td>\n","      <td>3.0</td>\n","      <td>29.000000</td>\n","      <td>0.000000</td>\n","      <td>10.000000</td>\n","      <td>0.000000</td>\n","      <td>14.0</td>\n","      <td>3.000000</td>\n","      <td>3.000000</td>\n","      <td>0.00</td>\n","      <td>2.00</td>\n","      <td>83.000000</td>\n","      <td>6.000000</td>\n","      <td>0.400000</td>\n","      <td>6.000000</td>\n","      <td>16.687000</td>\n","      <td>12.000000</td>\n","      <td>12.00</td>\n","      <td>0.122000</td>\n","      <td>7.870000</td>\n","      <td>13.400000</td>\n","      <td>25.559000</td>\n","      <td>1.160000</td>\n","      <td>4.1500</td>\n","      <td>5.000000</td>\n","    </tr>\n","    <tr>\n","      <th>464</th>\n","      <td>35.333333</td>\n","      <td>1.086000</td>\n","      <td>12405.753339</td>\n","      <td>88.012287</td>\n","      <td>5.956046</td>\n","      <td>-4.062017</td>\n","      <td>4.524067</td>\n","      <td>0.0</td>\n","      <td>15.8700</td>\n","      <td>-0.990000</td>\n","      <td>1757.733333</td>\n","      <td>18.000000</td>\n","      <td>11.666667</td>\n","      <td>1.036667</td>\n","      <td>112.666667</td>\n","      <td>3908.952667</td>\n","      <td>24.333333</td>\n","      <td>2.366667</td>\n","      <td>94.066667</td>\n","      <td>2.726667</td>\n","      <td>11.180933</td>\n","      <td>0.0000</td>\n","      <td>-5.642042</td>\n","      <td>3.092382</td>\n","      <td>3.896157</td>\n","      <td>0.0</td>\n","      <td>16.860000</td>\n","      <td>11.666667</td>\n","      <td>333.333333</td>\n","      <td>333.333333</td>\n","      <td>0.651333</td>\n","      <td>28.6920</td>\n","      <td>4.750000</td>\n","      <td>183.580600</td>\n","      <td>22.466667</td>\n","      <td>1.283333</td>\n","      <td>1071.600</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","      <td>0.00</td>\n","      <td>...</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","      <td>0.333333</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","      <td>0.666667</td>\n","      <td>0.000000</td>\n","      <td>0.00</td>\n","      <td>0.333333</td>\n","      <td>0.00</td>\n","      <td>0.666667</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>710.866667</td>\n","      <td>63.333333</td>\n","      <td>102.000000</td>\n","      <td>4.0</td>\n","      <td>5.333333</td>\n","      <td>2.666667</td>\n","      <td>0.666667</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>1.333333</td>\n","      <td>2.666667</td>\n","      <td>0.00</td>\n","      <td>2.00</td>\n","      <td>35.333333</td>\n","      <td>3.666667</td>\n","      <td>11.234667</td>\n","      <td>3.666667</td>\n","      <td>27.246000</td>\n","      <td>10.333333</td>\n","      <td>83.00</td>\n","      <td>0.651000</td>\n","      <td>18.178267</td>\n","      <td>523.666667</td>\n","      <td>43.290333</td>\n","      <td>0.426667</td>\n","      <td>1.1000</td>\n","      <td>2.666667</td>\n","    </tr>\n","    <tr>\n","      <th>465</th>\n","      <td>50.000000</td>\n","      <td>1.057500</td>\n","      <td>9306.473007</td>\n","      <td>127.014155</td>\n","      <td>5.880448</td>\n","      <td>-6.738583</td>\n","      <td>8.971338</td>\n","      <td>0.0</td>\n","      <td>13.7800</td>\n","      <td>-0.785000</td>\n","      <td>2145.050000</td>\n","      <td>50.000000</td>\n","      <td>9.500000</td>\n","      <td>1.075000</td>\n","      <td>131.000000</td>\n","      <td>9525.714500</td>\n","      <td>93.000000</td>\n","      <td>1.800000</td>\n","      <td>70.550000</td>\n","      <td>2.410000</td>\n","      <td>9.906075</td>\n","      <td>0.0000</td>\n","      <td>-8.024566</td>\n","      <td>3.026135</td>\n","      <td>3.812691</td>\n","      <td>0.0</td>\n","      <td>14.565000</td>\n","      <td>9.500000</td>\n","      <td>250.000000</td>\n","      <td>250.000000</td>\n","      <td>0.517000</td>\n","      <td>28.5215</td>\n","      <td>4.680000</td>\n","      <td>212.995450</td>\n","      <td>19.200000</td>\n","      <td>1.105000</td>\n","      <td>948.950</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","      <td>0.00</td>\n","      <td>...</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","      <td>0.500000</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","      <td>0.500000</td>\n","      <td>0.500000</td>\n","      <td>0.00</td>\n","      <td>0.500000</td>\n","      <td>0.00</td>\n","      <td>0.500000</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>731.400000</td>\n","      <td>53.500000</td>\n","      <td>111.000000</td>\n","      <td>11.0</td>\n","      <td>6.000000</td>\n","      <td>4.500000</td>\n","      <td>0.500000</td>\n","      <td>5.500000</td>\n","      <td>1.5</td>\n","      <td>1.000000</td>\n","      <td>2.000000</td>\n","      <td>0.00</td>\n","      <td>2.00</td>\n","      <td>50.000000</td>\n","      <td>4.500000</td>\n","      <td>12.851000</td>\n","      <td>4.500000</td>\n","      <td>17.558500</td>\n","      <td>55.500000</td>\n","      <td>37.50</td>\n","      <td>0.520000</td>\n","      <td>13.933700</td>\n","      <td>396.950000</td>\n","      <td>27.467000</td>\n","      <td>0.755000</td>\n","      <td>1.9500</td>\n","      <td>4.000000</td>\n","    </tr>\n","    <tr>\n","      <th>466</th>\n","      <td>36.000000</td>\n","      <td>0.948333</td>\n","      <td>12401.714393</td>\n","      <td>90.009237</td>\n","      <td>5.551922</td>\n","      <td>-5.312306</td>\n","      <td>7.005403</td>\n","      <td>0.0</td>\n","      <td>11.6300</td>\n","      <td>-1.115000</td>\n","      <td>1460.066667</td>\n","      <td>33.333333</td>\n","      <td>11.666667</td>\n","      <td>0.960000</td>\n","      <td>109.333333</td>\n","      <td>6350.952667</td>\n","      <td>62.000000</td>\n","      <td>1.200000</td>\n","      <td>94.066667</td>\n","      <td>2.753333</td>\n","      <td>11.143400</td>\n","      <td>0.0000</td>\n","      <td>-6.935308</td>\n","      <td>2.894388</td>\n","      <td>3.646700</td>\n","      <td>0.0</td>\n","      <td>12.745000</td>\n","      <td>11.666667</td>\n","      <td>333.333333</td>\n","      <td>333.333333</td>\n","      <td>0.650667</td>\n","      <td>28.8070</td>\n","      <td>3.193333</td>\n","      <td>143.133933</td>\n","      <td>18.566667</td>\n","      <td>1.203333</td>\n","      <td>1070.600</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","      <td>0.00</td>\n","      <td>...</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","      <td>0.333333</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","      <td>0.666667</td>\n","      <td>0.333333</td>\n","      <td>0.00</td>\n","      <td>0.333333</td>\n","      <td>0.00</td>\n","      <td>0.666667</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>505.866667</td>\n","      <td>64.666667</td>\n","      <td>95.333333</td>\n","      <td>8.0</td>\n","      <td>6.000000</td>\n","      <td>3.000000</td>\n","      <td>0.333333</td>\n","      <td>3.666667</td>\n","      <td>1.0</td>\n","      <td>1.333333</td>\n","      <td>2.666667</td>\n","      <td>0.00</td>\n","      <td>2.00</td>\n","      <td>36.000000</td>\n","      <td>3.666667</td>\n","      <td>8.834667</td>\n","      <td>3.666667</td>\n","      <td>23.411333</td>\n","      <td>37.000000</td>\n","      <td>29.00</td>\n","      <td>0.653333</td>\n","      <td>9.378267</td>\n","      <td>524.633333</td>\n","      <td>36.622667</td>\n","      <td>0.503333</td>\n","      <td>1.3000</td>\n","      <td>3.333333</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>467 rows × 86 columns</p>\n","</div>"],"text/plain":["     AtomicNumber_composition_average  ...  valence_composition_average\n","0                            6.000000  ...                     1.000000\n","1                           10.000000  ...                     4.000000\n","2                           19.000000  ...                     4.000000\n","3                           15.000000  ...                     2.000000\n","4                           28.000000  ...                     4.000000\n","..                                ...  ...                          ...\n","462                         60.500000  ...                     6.500000\n","463                         83.000000  ...                     5.000000\n","464                         35.333333  ...                     2.666667\n","465                         50.000000  ...                     4.000000\n","466                         36.000000  ...                     3.333333\n","\n","[467 rows x 86 columns]"]},"metadata":{"tags":[]},"execution_count":25}]},{"cell_type":"markdown","metadata":{"id":"m5ITre4zHYxf"},"source":["Next we'll see one of the benefits of using MAST-ML in this new way. Currently we don't have the same method impelemented in MAST-ML to remove highly correlated features. Previously adding this in would have been a good deal of work. But because we're using MAST-ML in this interactive notebook environment we can add in our own feature engineering steps that aren't included in the MAST-ML software. Below I just copied over the code from the previous notebook to filter highly correlated features"]},{"cell_type":"code","metadata":{"id":"YIQTsE-0HzQV","executionInfo":{"status":"ok","timestamp":1618306546816,"user_tz":-330,"elapsed":1015,"user":{"displayName":"AGAM GOYAL","photoUrl":"","userId":"12333294385015277225"}}},"source":["import numpy as np"],"execution_count":26,"outputs":[]},{"cell_type":"code","metadata":{"id":"PkM9M1aoGydV","executionInfo":{"status":"ok","timestamp":1618306550417,"user_tz":-330,"elapsed":1077,"user":{"displayName":"AGAM GOYAL","photoUrl":"","userId":"12333294385015277225"}}},"source":["features_corr_df = X.corr(method=\"pearson\").abs()\n","# Filter the features with correlation coefficients above 0.95\n","upper = features_corr_df.where(np.triu(np.ones(features_corr_df.shape), k=1).astype(np.bool))\n","to_drop = [column for column in upper.columns if any(upper[column] > 0.95)]\n","X = X.drop(columns=to_drop)"],"execution_count":27,"outputs":[]},{"cell_type":"code","metadata":{"id":"8L0jiPv1H4Cc","colab":{"base_uri":"https://localhost:8080/","height":411},"executionInfo":{"status":"ok","timestamp":1618306553486,"user_tz":-330,"elapsed":1013,"user":{"displayName":"AGAM GOYAL","photoUrl":"","userId":"12333294385015277225"}},"outputId":"0fe34f54-acc7-4e90-fe41-a93a7c992726"},"source":["X"],"execution_count":28,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>AtomicNumber_composition_average</th>\n","      <th>AtomicRadii_composition_average</th>\n","      <th>AtomicVolume_composition_average</th>\n","      <th>BCCefflatcnt_composition_average</th>\n","      <th>BCCenergy_pa_composition_average</th>\n","      <th>BCCfermi_composition_average</th>\n","      <th>BCCmagmom_composition_average</th>\n","      <th>BCCvolume_pa_composition_average</th>\n","      <th>BCCvolume_padiff_composition_average</th>\n","      <th>BoilingT_composition_average</th>\n","      <th>BulkModulus_composition_average</th>\n","      <th>Column_composition_average</th>\n","      <th>Density_composition_average</th>\n","      <th>ElasticModulus_composition_average</th>\n","      <th>ElectricalConductivity_composition_average</th>\n","      <th>ElectronAffinity_composition_average</th>\n","      <th>Electronegativity_composition_average</th>\n","      <th>FirstIonizationEnergy_composition_average</th>\n","      <th>GSbandgap_composition_average</th>\n","      <th>GSenergy_pa_composition_average</th>\n","      <th>GSmagmom_composition_average</th>\n","      <th>HHIp_composition_average</th>\n","      <th>HHIr_composition_average</th>\n","      <th>HeatCapacityMass_composition_average</th>\n","      <th>HeatCapacityMolar_composition_average</th>\n","      <th>HeatFusion_composition_average</th>\n","      <th>HeatVaporization_composition_average</th>\n","      <th>ICSDVolume_composition_average</th>\n","      <th>IonicRadii_composition_average</th>\n","      <th>IsAlkali_composition_average</th>\n","      <th>IsAlkalineEarth_composition_average</th>\n","      <th>IsBCC_composition_average</th>\n","      <th>IsBoron_composition_average</th>\n","      <th>IsCarbon_composition_average</th>\n","      <th>IsChalcogen_composition_average</th>\n","      <th>IsDBlock_composition_average</th>\n","      <th>IsFBlock_composition_average</th>\n","      <th>IsFCC_composition_average</th>\n","      <th>IsHalogen_composition_average</th>\n","      <th>IsHexagonal_composition_average</th>\n","      <th>IsMetal_composition_average</th>\n","      <th>IsMetalloid_composition_average</th>\n","      <th>IsMonoclinic_composition_average</th>\n","      <th>IsNonmetal_composition_average</th>\n","      <th>IsOrthorhombic_composition_average</th>\n","      <th>IsPnictide_composition_average</th>\n","      <th>IsRhombohedral_composition_average</th>\n","      <th>IsSimpleCubic_composition_average</th>\n","      <th>IsTetragonal_composition_average</th>\n","      <th>MeltingT_composition_average</th>\n","      <th>MendeleevNumber_composition_average</th>\n","      <th>MiracleRadius_composition_average</th>\n","      <th>NUnfilled_composition_average</th>\n","      <th>NValance_composition_average</th>\n","      <th>NdUnfilled_composition_average</th>\n","      <th>NdValence_composition_average</th>\n","      <th>NfUnfilled_composition_average</th>\n","      <th>NfValence_composition_average</th>\n","      <th>NpUnfilled_composition_average</th>\n","      <th>NpValence_composition_average</th>\n","      <th>NsUnfilled_composition_average</th>\n","      <th>NsValence_composition_average</th>\n","      <th>Polarizability_composition_average</th>\n","      <th>SecondIonizationEnergy_composition_average</th>\n","      <th>ShearModulus_composition_average</th>\n","      <th>SpaceGroupNumber_composition_average</th>\n","      <th>ThermalConductivity_composition_average</th>\n","      <th>ThermalExpansionCoefficient_composition_average</th>\n","      <th>ThirdIonizationEnergy_composition_average</th>\n","      <th>n_ws^third_composition_average</th>\n","      <th>valence_composition_average</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>6.000000</td>\n","      <td>1.135000</td>\n","      <td>9311.576313</td>\n","      <td>5.772386</td>\n","      <td>-1.346741</td>\n","      <td>-0.679877</td>\n","      <td>0.0</td>\n","      <td>12.4700</td>\n","      <td>-0.680417</td>\n","      <td>849.940000</td>\n","      <td>5.500000</td>\n","      <td>9.000000</td>\n","      <td>268.348000</td>\n","      <td>5.000000</td>\n","      <td>5.850000</td>\n","      <td>193.900000</td>\n","      <td>2.480000</td>\n","      <td>11.407259</td>\n","      <td>0.9850</td>\n","      <td>-1.783974</td>\n","      <td>0.0</td>\n","      <td>2200.000000</td>\n","      <td>2850.000000</td>\n","      <td>2.203000</td>\n","      <td>28.0820</td>\n","      <td>1.627500</td>\n","      <td>75.184900</td>\n","      <td>19.000000</td>\n","      <td>1.045000</td>\n","      <td>0.50</td>\n","      <td>0.0</td>\n","      <td>0.50</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.50</td>\n","      <td>0.0</td>\n","      <td>0.500000</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","      <td>0.500000</td>\n","      <td>0.000000</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.500000</td>\n","      <td>0.0</td>\n","      <td>253.595000</td>\n","      <td>47.000000</td>\n","      <td>76.000000</td>\n","      <td>1.0</td>\n","      <td>4.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.500000</td>\n","      <td>2.500000</td>\n","      <td>0.50</td>\n","      <td>1.50</td>\n","      <td>12.446000</td>\n","      <td>55.804000</td>\n","      <td>2.100000</td>\n","      <td>122.00</td>\n","      <td>42.363950</td>\n","      <td>923.000000</td>\n","      <td>92.579000</td>\n","      <td>0.490000</td>\n","      <td>1.000000</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>10.000000</td>\n","      <td>1.270000</td>\n","      <td>9169.525548</td>\n","      <td>6.658641</td>\n","      <td>-1.410040</td>\n","      <td>1.219961</td>\n","      <td>0.0</td>\n","      <td>18.5250</td>\n","      <td>-2.020417</td>\n","      <td>926.980000</td>\n","      <td>6.050000</td>\n","      <td>9.000000</td>\n","      <td>269.107000</td>\n","      <td>5.000000</td>\n","      <td>5.850000</td>\n","      <td>204.300000</td>\n","      <td>2.070000</td>\n","      <td>9.179675</td>\n","      <td>1.2465</td>\n","      <td>-1.827160</td>\n","      <td>0.0</td>\n","      <td>2200.000000</td>\n","      <td>2600.000000</td>\n","      <td>2.030500</td>\n","      <td>29.4045</td>\n","      <td>3.100000</td>\n","      <td>78.650000</td>\n","      <td>25.300000</td>\n","      <td>1.285000</td>\n","      <td>0.50</td>\n","      <td>0.0</td>\n","      <td>0.50</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.50</td>\n","      <td>0.0</td>\n","      <td>0.500000</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","      <td>0.500000</td>\n","      <td>0.500000</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>312.645000</td>\n","      <td>47.500000</td>\n","      <td>76.000000</td>\n","      <td>1.0</td>\n","      <td>4.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.500000</td>\n","      <td>2.500000</td>\n","      <td>0.50</td>\n","      <td>1.50</td>\n","      <td>13.257500</td>\n","      <td>50.224000</td>\n","      <td>2.100000</td>\n","      <td>146.50</td>\n","      <td>42.354450</td>\n","      <td>23.000000</td>\n","      <td>81.031000</td>\n","      <td>0.490000</td>\n","      <td>4.000000</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>19.000000</td>\n","      <td>1.345000</td>\n","      <td>32.035942</td>\n","      <td>6.919518</td>\n","      <td>-1.432083</td>\n","      <td>1.117212</td>\n","      <td>0.0</td>\n","      <td>21.0350</td>\n","      <td>-2.001667</td>\n","      <td>973.500000</td>\n","      <td>6.450000</td>\n","      <td>9.000000</td>\n","      <td>1827.500000</td>\n","      <td>5.000000</td>\n","      <td>5.850000</td>\n","      <td>192.200000</td>\n","      <td>1.970000</td>\n","      <td>8.602760</td>\n","      <td>0.7285</td>\n","      <td>-1.726456</td>\n","      <td>0.0</td>\n","      <td>3100.000000</td>\n","      <td>5550.000000</td>\n","      <td>2.028000</td>\n","      <td>50.2750</td>\n","      <td>4.142500</td>\n","      <td>80.912500</td>\n","      <td>43.350000</td>\n","      <td>1.360000</td>\n","      <td>0.50</td>\n","      <td>0.0</td>\n","      <td>0.50</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.50</td>\n","      <td>0.0</td>\n","      <td>0.500000</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","      <td>0.500000</td>\n","      <td>0.500000</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>359.745000</td>\n","      <td>48.000000</td>\n","      <td>76.000000</td>\n","      <td>1.0</td>\n","      <td>9.000000</td>\n","      <td>0.000000</td>\n","      <td>5.000000</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.500000</td>\n","      <td>2.500000</td>\n","      <td>0.50</td>\n","      <td>1.50</td>\n","      <td>13.692500</td>\n","      <td>49.219000</td>\n","      <td>2.100000</td>\n","      <td>146.50</td>\n","      <td>42.411000</td>\n","      <td>23.000000</td>\n","      <td>79.225500</td>\n","      <td>0.490000</td>\n","      <td>4.000000</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>15.000000</td>\n","      <td>1.560000</td>\n","      <td>23.705899</td>\n","      <td>6.704252</td>\n","      <td>-2.371630</td>\n","      <td>2.267697</td>\n","      <td>0.0</td>\n","      <td>19.1550</td>\n","      <td>-1.180000</td>\n","      <td>1676.250000</td>\n","      <td>18.750000</td>\n","      <td>4.500000</td>\n","      <td>2075.500000</td>\n","      <td>24.250000</td>\n","      <td>9.425000</td>\n","      <td>70.100000</td>\n","      <td>1.247500</td>\n","      <td>6.195887</td>\n","      <td>0.0000</td>\n","      <td>-2.431756</td>\n","      <td>0.0</td>\n","      <td>4150.000000</td>\n","      <td>4000.000000</td>\n","      <td>2.738250</td>\n","      <td>24.9525</td>\n","      <td>7.197500</td>\n","      <td>127.317500</td>\n","      <td>23.750000</td>\n","      <td>0.760000</td>\n","      <td>0.75</td>\n","      <td>0.0</td>\n","      <td>0.75</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","      <td>1.000000</td>\n","      <td>0.25</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.25</td>\n","      <td>0.25</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>566.212500</td>\n","      <td>22.000000</td>\n","      <td>152.750000</td>\n","      <td>1.5</td>\n","      <td>4.500000</td>\n","      <td>0.000000</td>\n","      <td>2.500000</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.750000</td>\n","      <td>0.750000</td>\n","      <td>0.75</td>\n","      <td>1.25</td>\n","      <td>19.901250</td>\n","      <td>61.611000</td>\n","      <td>8.150000</td>\n","      <td>213.25</td>\n","      <td>69.600000</td>\n","      <td>37.250000</td>\n","      <td>98.163250</td>\n","      <td>1.050000</td>\n","      <td>2.000000</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>28.000000</td>\n","      <td>1.440000</td>\n","      <td>32.101458</td>\n","      <td>7.343549</td>\n","      <td>-1.459519</td>\n","      <td>2.360221</td>\n","      <td>0.0</td>\n","      <td>25.9350</td>\n","      <td>-3.869167</td>\n","      <td>1036.150000</td>\n","      <td>9.350000</td>\n","      <td>9.000000</td>\n","      <td>2737.500000</td>\n","      <td>5.000000</td>\n","      <td>5.850000</td>\n","      <td>177.550000</td>\n","      <td>1.820000</td>\n","      <td>7.921489</td>\n","      <td>0.5310</td>\n","      <td>-1.687645</td>\n","      <td>0.0</td>\n","      <td>3900.000000</td>\n","      <td>4500.000000</td>\n","      <td>1.898000</td>\n","      <td>39.6450</td>\n","      <td>5.380000</td>\n","      <td>84.000000</td>\n","      <td>32.050000</td>\n","      <td>1.480000</td>\n","      <td>0.50</td>\n","      <td>0.0</td>\n","      <td>0.50</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.50</td>\n","      <td>0.0</td>\n","      <td>0.500000</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","      <td>0.500000</td>\n","      <td>0.500000</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>420.270000</td>\n","      <td>48.500000</td>\n","      <td>76.000000</td>\n","      <td>1.0</td>\n","      <td>9.000000</td>\n","      <td>0.000000</td>\n","      <td>5.000000</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.500000</td>\n","      <td>2.500000</td>\n","      <td>0.50</td>\n","      <td>1.50</td>\n","      <td>14.680000</td>\n","      <td>47.884500</td>\n","      <td>2.100000</td>\n","      <td>146.50</td>\n","      <td>42.574500</td>\n","      <td>66.500000</td>\n","      <td>77.725500</td>\n","      <td>0.490000</td>\n","      <td>4.000000</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>462</th>\n","      <td>60.500000</td>\n","      <td>1.422500</td>\n","      <td>40.865008</td>\n","      <td>8.158525</td>\n","      <td>-1.763974</td>\n","      <td>5.485714</td>\n","      <td>0.0</td>\n","      <td>33.9975</td>\n","      <td>-6.501250</td>\n","      <td>802.225000</td>\n","      <td>13.525000</td>\n","      <td>16.500000</td>\n","      <td>6150.000000</td>\n","      <td>8.500000</td>\n","      <td>0.225000</td>\n","      <td>248.975000</td>\n","      <td>2.500000</td>\n","      <td>9.659820</td>\n","      <td>0.7965</td>\n","      <td>-2.122475</td>\n","      <td>0.0</td>\n","      <td>5000.000000</td>\n","      <td>5100.000000</td>\n","      <td>0.191000</td>\n","      <td>47.2025</td>\n","      <td>8.596500</td>\n","      <td>60.425000</td>\n","      <td>40.700000</td>\n","      <td>1.907500</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.75</td>\n","      <td>0.0</td>\n","      <td>0.250000</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","      <td>0.750000</td>\n","      <td>0.750000</td>\n","      <td>0.25</td>\n","      <td>0.25</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>426.237500</td>\n","      <td>93.500000</td>\n","      <td>40.500000</td>\n","      <td>1.5</td>\n","      <td>20.000000</td>\n","      <td>0.000000</td>\n","      <td>10.000000</td>\n","      <td>0.000000</td>\n","      <td>3.5</td>\n","      <td>1.500000</td>\n","      <td>4.500000</td>\n","      <td>0.00</td>\n","      <td>2.00</td>\n","      <td>3.868750</td>\n","      <td>18.520000</td>\n","      <td>3.000000</td>\n","      <td>51.00</td>\n","      <td>2.304250</td>\n","      <td>68.600000</td>\n","      <td>31.139750</td>\n","      <td>0.290000</td>\n","      <td>6.500000</td>\n","    </tr>\n","    <tr>\n","      <th>463</th>\n","      <td>83.000000</td>\n","      <td>1.700000</td>\n","      <td>35.483459</td>\n","      <td>7.821898</td>\n","      <td>-3.895384</td>\n","      <td>8.463157</td>\n","      <td>0.0</td>\n","      <td>29.9100</td>\n","      <td>-3.040000</td>\n","      <td>1837.000000</td>\n","      <td>31.000000</td>\n","      <td>15.000000</td>\n","      <td>9780.000000</td>\n","      <td>34.000000</td>\n","      <td>0.900000</td>\n","      <td>110.000000</td>\n","      <td>2.020000</td>\n","      <td>7.285500</td>\n","      <td>0.0000</td>\n","      <td>-3.973694</td>\n","      <td>0.0</td>\n","      <td>5300.000000</td>\n","      <td>6000.000000</td>\n","      <td>0.122000</td>\n","      <td>25.5200</td>\n","      <td>11.106000</td>\n","      <td>179.000000</td>\n","      <td>35.300000</td>\n","      <td>1.030000</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","      <td>1.000000</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>1.00</td>\n","      <td>1.00</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>544.400000</td>\n","      <td>86.000000</td>\n","      <td>162.000000</td>\n","      <td>3.0</td>\n","      <td>29.000000</td>\n","      <td>0.000000</td>\n","      <td>10.000000</td>\n","      <td>0.000000</td>\n","      <td>14.0</td>\n","      <td>3.000000</td>\n","      <td>3.000000</td>\n","      <td>0.00</td>\n","      <td>2.00</td>\n","      <td>0.400000</td>\n","      <td>16.687000</td>\n","      <td>12.000000</td>\n","      <td>12.00</td>\n","      <td>7.870000</td>\n","      <td>13.400000</td>\n","      <td>25.559000</td>\n","      <td>1.160000</td>\n","      <td>5.000000</td>\n","    </tr>\n","    <tr>\n","      <th>464</th>\n","      <td>35.333333</td>\n","      <td>1.086000</td>\n","      <td>12405.753339</td>\n","      <td>5.956046</td>\n","      <td>-4.062017</td>\n","      <td>4.524067</td>\n","      <td>0.0</td>\n","      <td>15.8700</td>\n","      <td>-0.990000</td>\n","      <td>1757.733333</td>\n","      <td>18.000000</td>\n","      <td>11.666667</td>\n","      <td>3908.952667</td>\n","      <td>24.333333</td>\n","      <td>2.366667</td>\n","      <td>94.066667</td>\n","      <td>2.726667</td>\n","      <td>11.180933</td>\n","      <td>0.0000</td>\n","      <td>-5.642042</td>\n","      <td>0.0</td>\n","      <td>333.333333</td>\n","      <td>333.333333</td>\n","      <td>0.651333</td>\n","      <td>28.6920</td>\n","      <td>4.750000</td>\n","      <td>183.580600</td>\n","      <td>22.466667</td>\n","      <td>1.283333</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.666667</td>\n","      <td>0.0</td>\n","      <td>0.333333</td>\n","      <td>0.333333</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","      <td>0.333333</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","      <td>0.666667</td>\n","      <td>0.000000</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.666667</td>\n","      <td>0.0</td>\n","      <td>710.866667</td>\n","      <td>63.333333</td>\n","      <td>102.000000</td>\n","      <td>4.0</td>\n","      <td>5.333333</td>\n","      <td>2.666667</td>\n","      <td>0.666667</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>1.333333</td>\n","      <td>2.666667</td>\n","      <td>0.00</td>\n","      <td>2.00</td>\n","      <td>11.234667</td>\n","      <td>27.246000</td>\n","      <td>10.333333</td>\n","      <td>83.00</td>\n","      <td>18.178267</td>\n","      <td>523.666667</td>\n","      <td>43.290333</td>\n","      <td>0.426667</td>\n","      <td>2.666667</td>\n","    </tr>\n","    <tr>\n","      <th>465</th>\n","      <td>50.000000</td>\n","      <td>1.057500</td>\n","      <td>9306.473007</td>\n","      <td>5.880448</td>\n","      <td>-6.738583</td>\n","      <td>8.971338</td>\n","      <td>0.0</td>\n","      <td>13.7800</td>\n","      <td>-0.785000</td>\n","      <td>2145.050000</td>\n","      <td>50.000000</td>\n","      <td>9.500000</td>\n","      <td>9525.714500</td>\n","      <td>93.000000</td>\n","      <td>1.800000</td>\n","      <td>70.550000</td>\n","      <td>2.410000</td>\n","      <td>9.906075</td>\n","      <td>0.0000</td>\n","      <td>-8.024566</td>\n","      <td>0.0</td>\n","      <td>250.000000</td>\n","      <td>250.000000</td>\n","      <td>0.517000</td>\n","      <td>28.5215</td>\n","      <td>4.680000</td>\n","      <td>212.995450</td>\n","      <td>19.200000</td>\n","      <td>1.105000</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.500000</td>\n","      <td>0.0</td>\n","      <td>0.500000</td>\n","      <td>0.000000</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","      <td>0.500000</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","      <td>0.500000</td>\n","      <td>0.500000</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.500000</td>\n","      <td>0.0</td>\n","      <td>731.400000</td>\n","      <td>53.500000</td>\n","      <td>111.000000</td>\n","      <td>11.0</td>\n","      <td>6.000000</td>\n","      <td>4.500000</td>\n","      <td>0.500000</td>\n","      <td>5.500000</td>\n","      <td>1.5</td>\n","      <td>1.000000</td>\n","      <td>2.000000</td>\n","      <td>0.00</td>\n","      <td>2.00</td>\n","      <td>12.851000</td>\n","      <td>17.558500</td>\n","      <td>55.500000</td>\n","      <td>37.50</td>\n","      <td>13.933700</td>\n","      <td>396.950000</td>\n","      <td>27.467000</td>\n","      <td>0.755000</td>\n","      <td>4.000000</td>\n","    </tr>\n","    <tr>\n","      <th>466</th>\n","      <td>36.000000</td>\n","      <td>0.948333</td>\n","      <td>12401.714393</td>\n","      <td>5.551922</td>\n","      <td>-5.312306</td>\n","      <td>7.005403</td>\n","      <td>0.0</td>\n","      <td>11.6300</td>\n","      <td>-1.115000</td>\n","      <td>1460.066667</td>\n","      <td>33.333333</td>\n","      <td>11.666667</td>\n","      <td>6350.952667</td>\n","      <td>62.000000</td>\n","      <td>1.200000</td>\n","      <td>94.066667</td>\n","      <td>2.753333</td>\n","      <td>11.143400</td>\n","      <td>0.0000</td>\n","      <td>-6.935308</td>\n","      <td>0.0</td>\n","      <td>333.333333</td>\n","      <td>333.333333</td>\n","      <td>0.650667</td>\n","      <td>28.8070</td>\n","      <td>3.193333</td>\n","      <td>143.133933</td>\n","      <td>18.566667</td>\n","      <td>1.203333</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.666667</td>\n","      <td>0.0</td>\n","      <td>0.333333</td>\n","      <td>0.000000</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","      <td>0.333333</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","      <td>0.666667</td>\n","      <td>0.333333</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.666667</td>\n","      <td>0.0</td>\n","      <td>505.866667</td>\n","      <td>64.666667</td>\n","      <td>95.333333</td>\n","      <td>8.0</td>\n","      <td>6.000000</td>\n","      <td>3.000000</td>\n","      <td>0.333333</td>\n","      <td>3.666667</td>\n","      <td>1.0</td>\n","      <td>1.333333</td>\n","      <td>2.666667</td>\n","      <td>0.00</td>\n","      <td>2.00</td>\n","      <td>8.834667</td>\n","      <td>23.411333</td>\n","      <td>37.000000</td>\n","      <td>29.00</td>\n","      <td>9.378267</td>\n","      <td>524.633333</td>\n","      <td>36.622667</td>\n","      <td>0.503333</td>\n","      <td>3.333333</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>467 rows × 71 columns</p>\n","</div>"],"text/plain":["     AtomicNumber_composition_average  ...  valence_composition_average\n","0                            6.000000  ...                     1.000000\n","1                           10.000000  ...                     4.000000\n","2                           19.000000  ...                     4.000000\n","3                           15.000000  ...                     2.000000\n","4                           28.000000  ...                     4.000000\n","..                                ...  ...                          ...\n","462                         60.500000  ...                     6.500000\n","463                         83.000000  ...                     5.000000\n","464                         35.333333  ...                     2.666667\n","465                         50.000000  ...                     4.000000\n","466                         36.000000  ...                     3.333333\n","\n","[467 rows x 71 columns]"]},"metadata":{"tags":[]},"execution_count":28}]},{"cell_type":"markdown","metadata":{"id":"GXzjcRTxIJ7p"},"source":["Next up we perform the last feature engineering step, which was to normalize the features using scikit-learn's MinMaxScaler method. "]},{"cell_type":"code","metadata":{"id":"0RxphS-Zivb0","executionInfo":{"status":"ok","timestamp":1618306557704,"user_tz":-330,"elapsed":1702,"user":{"displayName":"AGAM GOYAL","photoUrl":"","userId":"12333294385015277225"}}},"source":["preprocessor = SklearnPreprocessor(preprocessor='MinMaxScaler', as_frame=True)\n","X = preprocessor.evaluate(X=X,\n","                          y=y, \n","                          savepath=savepath)"],"execution_count":29,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9szvPzBwzyPF"},"source":["## Section 5: Neural Network Optimization\n","---\n","In this section we'll start to analyze the NN from scikit-learn the MLPRegressor which stands for Multi-layer Perceptron Regressor. We can find the documentation here: https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPRegressor.html "]},{"cell_type":"markdown","metadata":{"id":"FlJyjBip0JY_"},"source":["We'll use the same assessment techniques as before where we use a combination of 5-Fold cross validation and the previously established test set to measure model predictive ability."]},{"cell_type":"markdown","metadata":{"id":"UburF8zQ2bRL"},"source":["During this activity we'll go through a number of different steps to optimize our neural network. For our first step let's use the grid search method outlined previously to grid over a number of different hyperparameters.\n","\n","Because the neural network model tends to take a bit longer to train we'll do a very rough grid of each hyperparameter so that we can run through quickly and identify what sorts of values are working best for each hyperparameter. After this initial run we can then narrow down either the range of values to get a more fine gride. Or we could start to exclude hyperparameters if we think we've found the best value for them overall."]},{"cell_type":"markdown","metadata":{"id":"9qvybcTLDfft"},"source":["We'll initially set up a rough grid over 3 hyperparameters:\n","\n","1) Alpha (Regularization)  \n","  Let's set a minimum value of 10^-8, a max of 10^2, with 5 grid points. Since we're varying over orders of magnitude it's easier to do this in log space, and our alpha values should be floats. so the string to setup this grid should look like 'x y z log float' with x and y being the exponents for the numbers and z being the number of grid points.  \n","2) Initial learning rate  \n","  For the learning rate we'll do the same thing but set the minimum to 10^-5 and max 10^1 with 5 grid points again.  \n","3) Activation  \n","  Activation is a categorical hyperparameter so it gets handled a bit differently. Looking at the sklearn documentation the available activation functions are: identity, logistic, tanh, and relu. Currently we have to do a bit of a hack to get it to work. but we can set these categories similarly in a string (inside quotes) with spaces in between. We also have to add an extra \"fake\" value as mastml is expecting to get a certain format and we're breaking that. so for the value input set it as 'identity logistic tanh relu fake' to have it try all the activation function options  \n","\n","  To include multiple hyperparameters in the grid search we seperate them by a semicolon   \n","  So an example would look like this:\n","  hyperparams = 'param1 ; param2 ; param3'  \n","  param_values = '1 5 3 log float ; 2 10 5 log float ; activation1 activation2 activation3 activation4 activation5'\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":592},"id":"HHfOoyGx3ewB","executionInfo":{"status":"error","timestamp":1618307733472,"user_tz":-330,"elapsed":3817,"user":{"displayName":"AGAM GOYAL","photoUrl":"","userId":"12333294385015277225"}},"outputId":"f8b5d1fa-760a-4538-a0d2-ddb2af3a388d"},"source":["default_model = SklearnModel(model='MLPRegressor')\n","models = [default_model]\n","selector = [NoSelect()]\n","metrics = ['r2_score', 'mean_absolute_error', 'root_mean_squared_error', 'rmse_over_stdev']\n","\n","### here's the key grid search settings we're going to edit\n","hyperparams = 'param1; param2; param3'\n","param_vals = '1 5 3 log float; 2 10 5 log float; activation1 activation2 activation3 activation4 activation5'\n","###\n","\n","grid1 = GridSearch(param_names=hyperparams,param_values=param_vals,scoring='neg_mean_squared_error')\n","grids = [grid1]\n","splitter = NoSplit()\n","splitter.evaluate(X=X,\n","                  y=y, \n","                  models=models,\n","                  preprocessor=None,\n","                  selectors=selector,\n","                  metrics=metrics,\n","                  savepath=savepath,\n","                  X_extra=X_extra,\n","                  leaveout_inds=X_testdata,\n","                  hyperopts = grids,\n","                  recalibrate_errors = True,\n","                  verbosity=3)"],"execution_count":32,"outputs":[{"output_type":"stream","text":["Warning: you have selected to recalibrate errors using a model that does not support error estimation. Automatically changing to set recalibrate_errors = False\n","You must specify either lin or log scaling for GridSearch\n","Hyperparameter optimization failed, likely due to inappropriate domain of values to optimize one or more parameters over. Please check your input file and the sklearn docs for the mode you are optimizing for the domain of correct values\n"],"name":"stdout"},{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/content/MAST-ML/mastml/hyper_opt.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, model, cv, savepath)\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m             \u001b[0mrst\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mestimator_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 710\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    711\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1150\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1151\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    688\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 689\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1040\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1041\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1042\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    776\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    778\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    503\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m         \u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mcloned_parameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    505\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mset_params\u001b[0;34m(self, **params)\u001b[0m\n\u001b[1;32m    235\u001b[0m                                  \u001b[0;34m'with `estimator.get_params().keys()`.'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m                                  (key, self))\n\u001b[0m\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Invalid parameter param1 for estimator MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n             hidden_layer_sizes=(100,), learning_rate='constant',\n             learning_rate_init=0.001, max_fun=15000, max_iter=200,\n             momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n             power_t=0.5, random_state=None, shuffle=True, solver='adam',\n             tol=0.0001, validation_fraction=0.1, verbose=False,\n             warm_start=False). Check the list of available parameters with `estimator.get_params().keys()`.","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-32-d3613e7e8f37>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m                   \u001b[0mhyperopts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m                   \u001b[0mrecalibrate_errors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m                   verbosity=3)\n\u001b[0m","\u001b[0;32m/content/MAST-ML/mastml/data_splitters.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, X, y, models, preprocessor, groups, hyperopts, selectors, metrics, plots, savepath, X_extra, leaveout_inds, best_run_metric, nested_CV, error_method, recalibrate_errors, verbosity)\u001b[0m\n\u001b[1;32m    291\u001b[0m                                                   \u001b[0merror_method\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m                                                   \u001b[0mrecalibrate_errors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m                                                   verbosity=verbosity)\n\u001b[0m\u001b[1;32m    294\u001b[0m                         \u001b[0msplit_outer_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/MAST-ML/mastml/data_splitters.py\u001b[0m in \u001b[0;36m_evaluate_split_sets\u001b[0;34m(self, X_splits, y_splits, train_inds, test_inds, model, selector, preprocessor, X_extra, groups, splitdir, hyperopt, metrics, plots, has_model_errors, error_method, recalibrate_errors, verbosity)\u001b[0m\n\u001b[1;32m    468\u001b[0m             self._evaluate_split(X_train, X_test, y_train, y_test, model_orig, preprocessor_orig, selector_orig,\n\u001b[1;32m    469\u001b[0m                                  \u001b[0mhyperopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplots\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 470\u001b[0;31m                                  splitpath, has_model_errors, X_extra_train, X_extra_test, error_method, verbosity)\n\u001b[0m\u001b[1;32m    471\u001b[0m             \u001b[0msplit_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/MAST-ML/mastml/data_splitters.py\u001b[0m in \u001b[0;36m_evaluate_split\u001b[0;34m(self, X_train, X_test, y_train, y_test, model, preprocessor, selector, hyperopt, metrics, plots, group, splitpath, has_model_errors, X_extra_train, X_extra_test, error_method, verbosity)\u001b[0m\n\u001b[1;32m    583\u001b[0m         \u001b[0;31m# Here evaluate hyperopt instance, if provided, and get updated model instance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhyperopt\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 585\u001b[0;31m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhyperopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msavepath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msplitpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    586\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/MAST-ML/mastml/hyper_opt.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, model, cv, savepath)\u001b[0m\n\u001b[1;32m    261\u001b[0m                                \u001b[0;34m' one or more parameters over. Please check your input file and the sklearn docs for the mode'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m                                ' you are optimizing for the domain of correct values')\n\u001b[0;32m--> 263\u001b[0;31m             \u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[0mbest_estimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrst\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mestimator_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'exit' is not defined"]}]},{"cell_type":"markdown","metadata":{"id":"ZkhSRj0PG0sy"},"source":["With this initial rough grid search complete let's go look through our results. Locate the \"gridsearch_mlpregressor...\" file in your run output and open it up to view how the model performed under each combination of hyperparameters. Because we varied so many at a time we can't make a simple one-dimensional learning curve.\n","\n","For this initial rough grid search what we're trying to identify is roughly what hyperparameter values are performing better so we can refine our search. for now let's just sort the values by the mean test score column so we can see what performed best. You can do this by opening the output in excel, or optionally you could read that output file back into the notebook here to do your analysis.\n"]},{"cell_type":"markdown","metadata":{"id":"D1OERiUJH6f9"},"source":["\n","For the top 10 or so performing combinations of hyperparameters let's ask ourselves a few questions:  \n","1) For each hyperparameter is there a common range for the numerical ones or common category for the categorical ones thatis clearly dominating? For example we might notice that a certain activation function is consistently performing well. Or that all of the learning rate values are around 10^-3. Take note of this for each hyperparameter, or if there isn't a clear trend note that as well.\n","\n","2) How quickly is performance dropping off during this rough grid search. For example find the performance for the top perfoming combination (for me it was {'activation': 'relu', 'alpha': 0.31622776601683794, 'learning_rate_init': 0.01}) and and for each numerical hyperparameter find the decrease in performance as each hyperparameter moves up and down one grid step. \n","\n","3) Finally for the numerical hyperparameters do any of them continuously decrease towards the boundary that we gave them? this might indicate we needed to do a wider grid search initially. Otherwise if we're finding minimum values within the previous range that means we can start to narrow the search."]},{"cell_type":"markdown","metadata":{"id":"GINsinIqKHQl"},"source":["Using the information from this previous analysis we'll establish our next search. Based on a quick look through the results I found the following:\n","- for learning rate it looks like 10^-1 to 10^-5 are performing best so let's move the outer bounds of the grid in to match those new values  \n","- for regularization values from 10^0 to 10^-8 were giving decent results so let's move those bounds in a bit on the high side  \n","- for the activation function all values are represented in the well performing models except the identity function (which makes sense). So we could make a few choices here. In the interest of time let's just pick the one that is most populated in the top 10 and use that going forward. Make sure to keep track of which one that is! For me it was the logistic function. \n","\n","Using these notes update your grid search from above and copy into the cell below to make your adjustments. To exclude the activation function from the grid search make sure to remove those sections. and add the extra input:  \n","activation='logistic'  \n","to the initial definition of the default_model object\n","\n","Also because we've removed one of the hyperparameters from the grid lets increase the grid density to 10."]},{"cell_type":"markdown","metadata":{"id":"JmvBxVwkNn_K"},"source":["**Note: this will take a bit to run**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dTtLDmp4LrHF","outputId":"756b9c66-0b07-4e98-dedb-ab953c9d5836"},"source":["# make sure to change the \"editthis\"\n","default_model = SklearnModel(model='MLPRegressor',activation=editthis)\n","models = [default_model]\n","selector = [NoSelect()]\n","metrics = ['r2_score', 'mean_absolute_error', 'root_mean_squared_error', 'rmse_over_stdev']\n","\n","### here's the key grid search settings we're going to edit\n","hyperparams = \n","param_vals = \n","###\n","\n","grid1 = GridSearch(param_names=hyperparams,param_values=param_vals,scoring='neg_mean_squared_error')\n","grids = [grid1]\n","splitter = NoSplit()\n","splitter.evaluate(X=X,\n","                  y=y, \n","                  models=models,\n","                  preprocessor=None,\n","                  selectors=selector,\n","                  metrics=metrics,\n","                  savepath=savepath,\n","                  X_extra=X_extra,\n","                  leaveout_inds=X_testdata,\n","                  hyperopts = grids,\n","                  recalibrate_errors = True,\n","                  verbosity=3)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Warning: you have selected to recalibrate errors using a model that does not support error estimation. Automatically changing to set recalibrate_errors = False\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"dikQ2EhRQbAM"},"source":["Conducting a similar analysis of the results as we did previously we'll refine the grid search one more time. Because we now have just two hyperparameters and both are numerical we could also make a heatmap of performance across the grid to identify which areas are performing well. For now, in the interest of time we'll skip making the full heatmap and again just do a quick scan of the top performing combinations of hyperparameters.\n","\n","For the learning rate hyperparameter it looks like performance drops consistently when the value goes below 10^-3, while the regularization doesn't have a clear trend. Instead many of the top combinations vary over many orders of magnitude. This suggests that the model isn't very sensitive to this parameter within the range we've given it so similar to before let's just pick and value to fix and only vary the learning rate. So let's set the regularizatin to:  \n","alpha=0.001\n","\n","Again because we've narrowed down the hyperparameters we can increaes the grid density of the remaining parameter. Lets set the number of grid points to 50 to do a much finer grid. Again copy the above settings to the cell below and make your adjustments."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ltQN07ZnSUdg","outputId":"a7bad849-16a2-420d-87b5-9abffdf8ec4d"},"source":["# make sure to change the \"editthis\" tags\n","default_model = SklearnModel(model='MLPRegressor',activation='logistic',alpha=editthis)\n","models = [default_model]\n","selector = [NoSelect()]\n","metrics = ['r2_score', 'mean_absolute_error', 'root_mean_squared_error', 'rmse_over_stdev']\n","\n","### here's the key grid search settings we're going to edit\n","hyperparams = \n","param_vals = \n","###\n","\n","grid1 = GridSearch(param_names=hyperparams,param_values=param_vals,scoring='neg_mean_squared_error')\n","grids = [grid1]\n","splitter = NoSplit()\n","splitter.evaluate(X=X,\n","                  y=y, \n","                  models=models,\n","                  preprocessor=None,\n","                  selectors=selector,\n","                  metrics=metrics,\n","                  savepath=savepath,\n","                  X_extra=X_extra,\n","                  leaveout_inds=X_testdata,\n","                  hyperopts = grids,\n","                  recalibrate_errors = True,\n","                  verbosity=3)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Warning: you have selected to recalibrate errors using a model that does not support error estimation. Automatically changing to set recalibrate_errors = False\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"EaCgN4iDVZ4F"},"source":["With this grid search what was the best learning rate?"]},{"cell_type":"markdown","metadata":{"id":"tCeiOZ6RSsmZ"},"source":["With this grid search complete we can say we've fairly thoroughly investigated various combinations of hyperparameters and found the best combination. However, one thing we haven't done yet it varied the neuron structure of the network. There is a hyperparameter which sets this, but because of how it's structured it doesn't mesh well with the grid search settings above. Instead we'll have to vary the structure manually.\n","\n","We do this with the \"hidden_layer_sizes\" hyperparameter which looks like this:  \n","hidden_layer_sizes = (100)   \n","hidden_layer_sizes = (100,100)\n","\n","The number inside the parentheses specify the number of neurons in each layer and we can add more layers by adding more commas with additional numbers"]},{"cell_type":"markdown","metadata":{"id":"XwA68p_mUIUy"},"source":["by default Scikit-learn sets the network to have one layer with 100 neurons. As a last optimization step let's try to vary this structure and see how it affects the results.\n","\n","Just like we did previously when we fixed the other hyperparameters outside of the grid search we can do the same by adding in the hidden_layer_sizes hyperparameter. And we'll try a few different configurations:\n","\n","1) Reduce the number of neurons in the single layer to 50. How does this affect the results? Does the simple model cause a drop in performance?\n","\n","2) If it doesn't, keep decreasing by 10 until you see a significant change in performance. Note: for me this occurred around 20 neurons.\n","\n","3) Let's try multiple layers. Using the previous result of 20 neurons lets increase the number of layers to 2 and then 3 and see how the performance is affected. Did increasing the number of layers affect performance? (also note: this isn't the correct way to optimize this structure overall, we're just trying a few different combinations).\n","\n","4) based on these results try to find the best structure with the previouosly set hyperparameters. Report in your slides the best model you find!\n"]},{"cell_type":"code","metadata":{"id":"n-H7NlnOVkhj"},"source":["# make sure to edit the \"editthis\" sections below.\n","default_model = SklearnModel(model='MLPRegressor',activation='tempeditthis',alpha=editthis,learning_rate_init=editthis,hidden_layer_sizes=(editthis))\n","models = [default_model]\n","selector = [NoSelect()]\n","metrics = ['r2_score', 'mean_absolute_error', 'root_mean_squared_error', 'rmse_over_stdev']\n","\n","splitter = SklearnDataSplitter(splitter='RepeatedKFold', n_repeats=3, n_splits=5)\n","splitter.evaluate(X=X,\n","                  y=y,\n","                  models=models,\n","                  preprocessor=None,\n","                  selectors=selector,\n","                  metrics=metrics,\n","                  savepath=savepath,\n","                  X_extra=X_extra,\n","                  leaveout_inds=X_testdata,\n","                  verbosity=3)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8C7WpP0sBphS"},"source":[""],"execution_count":null,"outputs":[]}]}