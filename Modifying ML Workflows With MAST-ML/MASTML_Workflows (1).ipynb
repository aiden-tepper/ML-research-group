{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"MASTML_Workflows.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"VdLbblbT3fIB"},"source":["# MAST-ML Workflow Activity\n","\n","\n","---\n","This activity serves as an introduction to the more pythonic way of working with the MAST-ML software. During the activity we'll see how to set up some basic MAST-ML workflows which mirror workflows previously explored via:\n","- Citrination\n","- Nanohub Introduction to Machine Learning for Materials Science\n","\n","Throughout the insstructions we'll reference directly back to the Nanohub notebook. I'ld advise you have that open in a second tab to refer back to. you can find that notebook here:  \n","www.nanohub.org/tools/intromllab \n","\n","The overall goal is to reproduce those workflows using the MAST-ML software, learn how to execute calls to MAST-ML, and how to find and anlyze the results.\n","\n","This notebook is setup in a linear fashion where working from top to bottom will execute the full workflow.\n"]},{"cell_type":"markdown","metadata":{"id":"6UxJ6oB54hv9"},"source":["## Section 1: Setting up our Google Colab Environment\n","---\n","Before running any code we first need to install MAST-ML as well as it's dependencies into the colab environment. \n"]},{"cell_type":"markdown","metadata":{"id":"_pB0qEmM48BY"},"source":["Clone the MAST-ML code into the content directory to the left. You should be able to see a new \"MAST-ML\" directory after running this cell."]},{"cell_type":"code","metadata":{"id":"xdEXmdzP7kWN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1616446206223,"user_tz":300,"elapsed":285,"user":{"displayName":"HAIRONG YIN","photoUrl":"","userId":"16460850665293890760"}},"outputId":"9df5e98d-c1b9-49be-86e6-c4d80418d860"},"source":["!git clone --single-branch --branch skunkworks_s21 https://github.com/uw-cmg/MAST-ML"],"execution_count":1,"outputs":[{"output_type":"stream","text":["fatal: destination path 'MAST-ML' already exists and is not an empty directory.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"HcruaZzR5T-V"},"source":["Next, we install the required dependencies of MAST-ML to our Colab session"]},{"cell_type":"code","metadata":{"id":"hqhQ2pXcvCwU","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"ab7c4047-f0cb-4ab0-c6a4-e175bc1a2b64"},"source":["!pip install -r MAST-ML/requirements.txt\n","!pip install pymatgen==2020.12.31\n","#!pip install scikit-learn=='0.23.2'"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting citrination-client\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/61/49/c0af91084172f6a6aa7d625651ec366c85a4fd717c5b4fa0e014d1953d6e/citrination-client-6.5.1.tar.gz (54kB)\n","\u001b[K     |████████████████████████████████| 61kB 2.9MB/s \n","\u001b[?25hCollecting dlhub_sdk\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/cd/02ad247cf7df4467b63dec57e2c8d8f5fe64330bf6da61e6ac6cddcde149/dlhub_sdk-0.9.4-py2.py3-none-any.whl (41kB)\n","\u001b[K     |████████████████████████████████| 51kB 3.4MB/s \n","\u001b[?25hCollecting globus_nexus_client\n","  Downloading https://files.pythonhosted.org/packages/52/ca/a0e2c03aeea3e4b3b3256ab309e24fb5227ebaf92aabca56b6dfc3cc758a/globus_nexus_client-0.3.0-py2.py3-none-any.whl\n","Collecting globus_sdk\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/92/a4/57b628cc5509eeb8361eb87506a3aea2078ca9c4e4ffaebc88280cdf7f40/globus_sdk-2.0.1-py2.py3-none-any.whl (85kB)\n","\u001b[K     |████████████████████████████████| 92kB 4.0MB/s \n","\u001b[?25hCollecting matminer\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/18/67/319db03366448bf367f6239598da2da0021389b02a7f874380ee3c193890/matminer-0.6.5.tar.gz (5.8MB)\n","\u001b[K     |████████████████████████████████| 5.8MB 6.0MB/s \n","\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from -r MAST-ML/requirements.txt (line 6)) (3.2.2)\n","Collecting mdf_forge\n","  Downloading https://files.pythonhosted.org/packages/6f/0c/697e48caaabc83e071c222dc6d25ec0a924c69d4cf8f990964f47091b8d2/mdf_forge-0.7.6-py2.py3-none-any.whl\n","Collecting mdf-toolbox\n","  Downloading https://files.pythonhosted.org/packages/f5/44/45ed3b256d744891384d13088c12a23baaa2e395b341c3ab03c18001f715/mdf_toolbox-0.5.7-py2.py3-none-any.whl\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from -r MAST-ML/requirements.txt (line 9)) (1.19.5)\n","Requirement already satisfied: openpyxl in /usr/local/lib/python3.7/dist-packages (from -r MAST-ML/requirements.txt (line 10)) (2.5.9)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from -r MAST-ML/requirements.txt (line 11)) (1.1.5)\n","Collecting pymatgen\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b4/db/c1891589a2b3133658f58c883eda4ff25769036363f662e1af5d3ed1394c/pymatgen-2022.0.5.tar.gz (3.4MB)\n","\u001b[K     |████████████████████████████████| 3.4MB 31.5MB/s \n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n","    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from -r MAST-ML/requirements.txt (line 13)) (0.22.2.post1)\n","Collecting scikit-optimize\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8b/03/be33e89f55866065a02e515c5b319304a801a9f1027a9b311a9b1d1f8dc7/scikit_optimize-0.8.1-py2.py3-none-any.whl (101kB)\n","\u001b[K     |████████████████████████████████| 102kB 7.4MB/s \n","\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from -r MAST-ML/requirements.txt (line 15)) (1.4.1)\n","Collecting sphinx-automodapi\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/16/08/83a3ee2cd420043538d195f024caac76dc2567a266361d95bb9344ab5594/sphinx_automodapi-0.13-py3-none-any.whl (75kB)\n","\u001b[K     |████████████████████████████████| 81kB 4.5MB/s \n","\u001b[?25hRequirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.7/dist-packages (from citrination-client->-r MAST-ML/requirements.txt (line 1)) (2.23.0)\n","Collecting pypif\n","  Downloading https://files.pythonhosted.org/packages/1e/04/a59e5ebacaed2800678467d9fcf511d249bac9b1b692a8fba0072cb09a49/pypif-2.1.2.tar.gz\n","Requirement already satisfied: six<2 in /usr/local/lib/python3.7/dist-packages (from citrination-client->-r MAST-ML/requirements.txt (line 1)) (1.15.0)\n","Collecting pyyaml>=5.1.2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7a/a5/393c087efdc78091afa2af9f1378762f9821c9c1d7a22c5753fb5ac5f97a/PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636kB)\n","\u001b[K     |████████████████████████████████| 645kB 42.3MB/s \n","\u001b[?25hCollecting jsonschema>=3.2.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c5/8f/51e89ce52a085483359217bc72cdbf6e75ee595d5b1d4b5ade40c7e018b8/jsonschema-3.2.0-py2.py3-none-any.whl (56kB)\n","\u001b[K     |████████████████████████████████| 61kB 4.7MB/s \n","\u001b[?25hCollecting funcx>=0.0.5\n","  Downloading https://files.pythonhosted.org/packages/5b/c0/359be86c580f0d261753651d4da4f15faa6f866be00613d2888035154d10/funcx-0.0.5-py3-none-any.whl\n","Collecting pyjwt[crypto]<2.0.0,>=1.5.3\n","  Downloading https://files.pythonhosted.org/packages/87/8b/6a9f14b5f781697e51259d81657e6048fd31a113229cf346880bb7545565/PyJWT-1.7.1-py2.py3-none-any.whl\n","Collecting tqdm>=4.46.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f8/3e/2730d0effc282960dbff3cf91599ad0d8f3faedc8e75720fdf224b31ab24/tqdm-4.59.0-py2.py3-none-any.whl (74kB)\n","\u001b[K     |████████████████████████████████| 81kB 6.6MB/s \n","\u001b[?25hRequirement already satisfied: pymongo>=3.10.1 in /usr/local/lib/python3.7/dist-packages (from matminer->-r MAST-ML/requirements.txt (line 5)) (3.11.3)\n","Collecting pint>=0.11\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/33/de/53a77b82553579affab7438d299f850acbc1c4dd741c5ce52594513cb0ef/Pint-0.17-py2.py3-none-any.whl (204kB)\n","\u001b[K     |████████████████████████████████| 215kB 42.8MB/s \n","\u001b[?25hCollecting plotly>=4.8.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1f/f6/bd3c17c8003b6641df1228e80e1acac97ed8402635e46c2571f8e1ef63af/plotly-4.14.3-py2.py3-none-any.whl (13.2MB)\n","\u001b[K     |████████████████████████████████| 13.2MB 39.4MB/s \n","\u001b[?25hCollecting future>=0.18.2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/45/0b/38b06fd9b92dc2b68d58b75f900e97884c45bedd2ff83203d933cf5851c9/future-0.18.2.tar.gz (829kB)\n","\u001b[K     |████████████████████████████████| 829kB 37.9MB/s \n","\u001b[?25hRequirement already satisfied: sympy>=1.6 in /usr/local/lib/python3.7/dist-packages (from matminer->-r MAST-ML/requirements.txt (line 5)) (1.7.1)\n","Collecting monty>=3.0.2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/41/47/e6f045cd69f24df0b4ddd55fab329c079b7c9ce978a32431dce904f6a1d6/monty-2021.3.3-py3-none-any.whl (63kB)\n","\u001b[K     |████████████████████████████████| 71kB 5.4MB/s \n","\u001b[?25hRequirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r MAST-ML/requirements.txt (line 6)) (2.4.7)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r MAST-ML/requirements.txt (line 6)) (1.3.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r MAST-ML/requirements.txt (line 6)) (0.10.0)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r MAST-ML/requirements.txt (line 6)) (2.8.1)\n","Collecting fair-research-login>=0.1.5\n","  Downloading https://files.pythonhosted.org/packages/89/a6/3239efa5150d9cb52af90d246ca46a405eefdaee503e77bf84023dbd2752/fair_research_login-0.2.0-py2.py3-none-any.whl\n","Requirement already satisfied: jdcal in /usr/local/lib/python3.7/dist-packages (from openpyxl->-r MAST-ML/requirements.txt (line 10)) (1.4.1)\n","Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.7/dist-packages (from openpyxl->-r MAST-ML/requirements.txt (line 10)) (1.0.1)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->-r MAST-ML/requirements.txt (line 11)) (2018.9)\n","Collecting uncertainties>=3.1.4\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/45/41/fc7e7b73b603e7c2c9e040b7aa8caf4a88d74b6faa567601ed82b6f0d8e1/uncertainties-3.1.5-py2.py3-none-any.whl (246kB)\n","\u001b[K     |████████████████████████████████| 256kB 39.7MB/s \n","\u001b[?25hRequirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from pymatgen->-r MAST-ML/requirements.txt (line 12)) (0.8.9)\n","Requirement already satisfied: palettable>=3.1.1 in /usr/local/lib/python3.7/dist-packages (from pymatgen->-r MAST-ML/requirements.txt (line 12)) (3.3.0)\n","Collecting ruamel.yaml>=0.15.6\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ed/c3/4c823dac2949a6baf36a4987d04c50d30184147393ba6f4bfb4c67d15a13/ruamel.yaml-0.16.13-py2.py3-none-any.whl (111kB)\n","\u001b[K     |████████████████████████████████| 112kB 40.6MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from pymatgen->-r MAST-ML/requirements.txt (line 12)) (3.7.4.3)\n","Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.7/dist-packages (from pymatgen->-r MAST-ML/requirements.txt (line 12)) (2.5)\n","Collecting spglib>=1.9.9.44\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4b/98/fa4760b9c71e2eace5a60b85dbf36dece49c379f8291cf1203056f287766/spglib-1.16.1-cp37-cp37m-manylinux2010_x86_64.whl (296kB)\n","\u001b[K     |████████████████████████████████| 296kB 38.6MB/s \n","\u001b[?25hRequirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->-r MAST-ML/requirements.txt (line 13)) (1.0.1)\n","Collecting pyaml>=16.9\n","  Downloading https://files.pythonhosted.org/packages/15/c4/1310a054d33abc318426a956e7d6df0df76a6ddfa9c66f6310274fb75d42/pyaml-20.4.0-py2.py3-none-any.whl\n","Requirement already satisfied: sphinx>=1.7 in /usr/local/lib/python3.7/dist-packages (from sphinx-automodapi->-r MAST-ML/requirements.txt (line 16)) (1.8.5)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->citrination-client->-r MAST-ML/requirements.txt (line 1)) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->citrination-client->-r MAST-ML/requirements.txt (line 1)) (2020.12.5)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->citrination-client->-r MAST-ML/requirements.txt (line 1)) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->citrination-client->-r MAST-ML/requirements.txt (line 1)) (1.24.3)\n","Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.2.0->dlhub_sdk->-r MAST-ML/requirements.txt (line 2)) (20.3.0)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.2.0->dlhub_sdk->-r MAST-ML/requirements.txt (line 2)) (3.7.2)\n","Requirement already satisfied: pyrsistent>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.2.0->dlhub_sdk->-r MAST-ML/requirements.txt (line 2)) (0.17.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.2.0->dlhub_sdk->-r MAST-ML/requirements.txt (line 2)) (54.1.2)\n","Collecting sphinx-rtd-theme\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/76/81/d5af3a50a45ee4311ac2dac5b599d69f68388401c7a4ca902e0e450a9f94/sphinx_rtd_theme-0.5.1-py2.py3-none-any.whl (2.8MB)\n","\u001b[K     |████████████████████████████████| 2.8MB 40.1MB/s \n","\u001b[?25hRequirement already satisfied: dill>=0.3 in /usr/local/lib/python3.7/dist-packages (from funcx>=0.0.5->dlhub_sdk->-r MAST-ML/requirements.txt (line 2)) (0.3.3)\n","Collecting texttable\n","  Downloading https://files.pythonhosted.org/packages/06/f5/46201c428aebe0eecfa83df66bf3e6caa29659dbac5a56ddfd83cae0d4a4/texttable-1.6.3-py2.py3-none-any.whl\n","Collecting parsl==0.9.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ad/8b/91b10b35b9d43ba3fc456430a4c1b2b514d27623989d7354f2152c6bc8de/parsl-0.9.0-py3-none-any.whl (415kB)\n","\u001b[K     |████████████████████████████████| 419kB 32.7MB/s \n","\u001b[?25hCollecting python-daemon\n","  Downloading https://files.pythonhosted.org/packages/b1/cc/2ab0d910548de45eaaa50d0372387951d9005c356a44c6858db12dc6b2b7/python_daemon-2.3.0-py2.py3-none-any.whl\n","Collecting typer>=0.3.0\n","  Downloading https://files.pythonhosted.org/packages/90/34/d138832f6945432c638f32137e6c79a3b682f06a63c488dcfaca6b166c64/typer-0.3.2-py3-none-any.whl\n","Collecting configobj\n","  Downloading https://files.pythonhosted.org/packages/64/61/079eb60459c44929e684fa7d9e2fdca403f67d64dd9dbac27296be2e0fab/configobj-5.0.6.tar.gz\n","Collecting nbsphinx\n","  Downloading https://files.pythonhosted.org/packages/cb/9a/3cf800179121da13d95cce3aa617d667d5f2983f87d0ab695ceed6d5ef78/nbsphinx-0.8.2-py3-none-any.whl\n","Collecting cryptography>=1.4; extra == \"crypto\"\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f8/1f/acde6ff69864c5e78b56488e3afd93c1ccc8c2651186e2a5f93d93f64859/cryptography-3.4.6-cp36-abi3-manylinux2014_x86_64.whl (3.2MB)\n","\u001b[K     |████████████████████████████████| 3.2MB 41.0MB/s \n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from pint>=0.11->matminer->-r MAST-ML/requirements.txt (line 5)) (20.9)\n","Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.7/dist-packages (from plotly>=4.8.1->matminer->-r MAST-ML/requirements.txt (line 5)) (1.3.3)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.7/dist-packages (from sympy>=1.6->matminer->-r MAST-ML/requirements.txt (line 5)) (1.2.1)\n","Collecting ruamel.yaml.clib>=0.1.2; platform_python_implementation == \"CPython\" and python_version < \"3.10\"\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5e/6e/f652c56bbb2c3d3fca252ffc7c0358597f57a1bbdf484dac683054950c63/ruamel.yaml.clib-0.2.2-cp37-cp37m-manylinux1_x86_64.whl (547kB)\n","\u001b[K     |████████████████████████████████| 552kB 20.9MB/s \n","\u001b[?25hRequirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from networkx>=2.2->pymatgen->-r MAST-ML/requirements.txt (line 12)) (4.4.2)\n","Requirement already satisfied: babel!=2.0,>=1.3 in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.7->sphinx-automodapi->-r MAST-ML/requirements.txt (line 16)) (2.9.0)\n","Requirement already satisfied: imagesize in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.7->sphinx-automodapi->-r MAST-ML/requirements.txt (line 16)) (1.2.0)\n","Requirement already satisfied: sphinxcontrib-websupport in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.7->sphinx-automodapi->-r MAST-ML/requirements.txt (line 16)) (1.2.4)\n","Requirement already satisfied: snowballstemmer>=1.1 in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.7->sphinx-automodapi->-r MAST-ML/requirements.txt (line 16)) (2.1.0)\n","Requirement already satisfied: Pygments>=2.0 in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.7->sphinx-automodapi->-r MAST-ML/requirements.txt (line 16)) (2.6.1)\n","Requirement already satisfied: Jinja2>=2.3 in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.7->sphinx-automodapi->-r MAST-ML/requirements.txt (line 16)) (2.11.3)\n","Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.7->sphinx-automodapi->-r MAST-ML/requirements.txt (line 16)) (0.7.12)\n","Requirement already satisfied: docutils>=0.11 in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.7->sphinx-automodapi->-r MAST-ML/requirements.txt (line 16)) (0.16)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->jsonschema>=3.2.0->dlhub_sdk->-r MAST-ML/requirements.txt (line 2)) (3.4.1)\n","Collecting paramiko\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/95/19/124e9287b43e6ff3ebb9cdea3e5e8e88475a873c05ccdf8b7e20d2c4201e/paramiko-2.7.2-py2.py3-none-any.whl (206kB)\n","\u001b[K     |████████████████████████████████| 215kB 34.4MB/s \n","\u001b[?25hRequirement already satisfied: pyzmq>=17.1.2 in /usr/local/lib/python3.7/dist-packages (from parsl==0.9.0->funcx>=0.0.5->dlhub_sdk->-r MAST-ML/requirements.txt (line 2)) (22.0.3)\n","Requirement already satisfied: ipykernel in /usr/local/lib/python3.7/dist-packages (from parsl==0.9.0->funcx>=0.0.5->dlhub_sdk->-r MAST-ML/requirements.txt (line 2)) (4.10.1)\n","Collecting ipyparallel\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3b/e9/03a9189eb39276396309faf28bf833b4328befe4513bbf375b811a36a076/ipyparallel-6.3.0-py3-none-any.whl (199kB)\n","\u001b[K     |████████████████████████████████| 204kB 44.7MB/s \n","\u001b[?25hRequirement already satisfied: tblib in /usr/local/lib/python3.7/dist-packages (from parsl==0.9.0->funcx>=0.0.5->dlhub_sdk->-r MAST-ML/requirements.txt (line 2)) (1.7.0)\n","Requirement already satisfied: typeguard in /usr/local/lib/python3.7/dist-packages (from parsl==0.9.0->funcx>=0.0.5->dlhub_sdk->-r MAST-ML/requirements.txt (line 2)) (2.7.1)\n","Collecting psutil>=5.5.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/84/da/f7efdcf012b51506938553dbe302aecc22f3f43abd5cffa8320e8e0588d5/psutil-5.8.0-cp37-cp37m-manylinux2010_x86_64.whl (296kB)\n","\u001b[K     |████████████████████████████████| 296kB 30.5MB/s \n","\u001b[?25hCollecting lockfile>=0.10\n","  Downloading https://files.pythonhosted.org/packages/c8/22/9460e311f340cb62d26a38c419b1381b8593b0bb6b5d1f056938b086d362/lockfile-0.12.2-py2.py3-none-any.whl\n","Requirement already satisfied: click<7.2.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer>=0.3.0->funcx>=0.0.5->dlhub_sdk->-r MAST-ML/requirements.txt (line 2)) (7.1.2)\n","Requirement already satisfied: nbconvert!=5.4 in /usr/local/lib/python3.7/dist-packages (from nbsphinx->funcx>=0.0.5->dlhub_sdk->-r MAST-ML/requirements.txt (line 2)) (5.6.1)\n","Requirement already satisfied: traitlets in /usr/local/lib/python3.7/dist-packages (from nbsphinx->funcx>=0.0.5->dlhub_sdk->-r MAST-ML/requirements.txt (line 2)) (5.0.5)\n","Requirement already satisfied: nbformat in /usr/local/lib/python3.7/dist-packages (from nbsphinx->funcx>=0.0.5->dlhub_sdk->-r MAST-ML/requirements.txt (line 2)) (5.1.2)\n","Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=1.4; extra == \"crypto\"->pyjwt[crypto]<2.0.0,>=1.5.3->globus_sdk->-r MAST-ML/requirements.txt (line 4)) (1.14.5)\n","Requirement already satisfied: sphinxcontrib-serializinghtml in /usr/local/lib/python3.7/dist-packages (from sphinxcontrib-websupport->sphinx>=1.7->sphinx-automodapi->-r MAST-ML/requirements.txt (line 16)) (1.1.4)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2>=2.3->sphinx>=1.7->sphinx-automodapi->-r MAST-ML/requirements.txt (line 16)) (1.1.1)\n","Collecting pynacl>=1.0.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9d/57/2f5e6226a674b2bcb6db531e8b383079b678df5b10cdaa610d6cf20d77ba/PyNaCl-1.4.0-cp35-abi3-manylinux1_x86_64.whl (961kB)\n","\u001b[K     |████████████████████████████████| 962kB 28.8MB/s \n","\u001b[?25hCollecting bcrypt>=3.1.3\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/26/70/6d218afbe4c73538053c1016dd631e8f25fffc10cd01f5c272d7acf3c03d/bcrypt-3.2.0-cp36-abi3-manylinux2010_x86_64.whl (63kB)\n","\u001b[K     |████████████████████████████████| 71kB 5.0MB/s \n","\u001b[?25hRequirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->parsl==0.9.0->funcx>=0.0.5->dlhub_sdk->-r MAST-ML/requirements.txt (line 2)) (5.5.0)\n","Requirement already satisfied: jupyter-client in /usr/local/lib/python3.7/dist-packages (from ipykernel->parsl==0.9.0->funcx>=0.0.5->dlhub_sdk->-r MAST-ML/requirements.txt (line 2)) (5.3.5)\n","Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->parsl==0.9.0->funcx>=0.0.5->dlhub_sdk->-r MAST-ML/requirements.txt (line 2)) (5.1.1)\n","Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from ipyparallel->parsl==0.9.0->funcx>=0.0.5->dlhub_sdk->-r MAST-ML/requirements.txt (line 2)) (0.2.0)\n","Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert!=5.4->nbsphinx->funcx>=0.0.5->dlhub_sdk->-r MAST-ML/requirements.txt (line 2)) (1.4.3)\n","Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert!=5.4->nbsphinx->funcx>=0.0.5->dlhub_sdk->-r MAST-ML/requirements.txt (line 2)) (0.3)\n","Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert!=5.4->nbsphinx->funcx>=0.0.5->dlhub_sdk->-r MAST-ML/requirements.txt (line 2)) (0.7.1)\n","Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert!=5.4->nbsphinx->funcx>=0.0.5->dlhub_sdk->-r MAST-ML/requirements.txt (line 2)) (0.4.4)\n","Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert!=5.4->nbsphinx->funcx>=0.0.5->dlhub_sdk->-r MAST-ML/requirements.txt (line 2)) (3.3.0)\n","Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert!=5.4->nbsphinx->funcx>=0.0.5->dlhub_sdk->-r MAST-ML/requirements.txt (line 2)) (0.8.4)\n","Requirement already satisfied: jupyter-core in /usr/local/lib/python3.7/dist-packages (from nbconvert!=5.4->nbsphinx->funcx>=0.0.5->dlhub_sdk->-r MAST-ML/requirements.txt (line 2)) (4.7.1)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=1.4; extra == \"crypto\"->pyjwt[crypto]<2.0.0,>=1.5.3->globus_sdk->-r MAST-ML/requirements.txt (line 4)) (2.20)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->parsl==0.9.0->funcx>=0.0.5->dlhub_sdk->-r MAST-ML/requirements.txt (line 2)) (0.7.5)\n","Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->parsl==0.9.0->funcx>=0.0.5->dlhub_sdk->-r MAST-ML/requirements.txt (line 2)) (4.8.0)\n","Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->parsl==0.9.0->funcx>=0.0.5->dlhub_sdk->-r MAST-ML/requirements.txt (line 2)) (0.8.1)\n","Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->parsl==0.9.0->funcx>=0.0.5->dlhub_sdk->-r MAST-ML/requirements.txt (line 2)) (1.0.18)\n","Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert!=5.4->nbsphinx->funcx>=0.0.5->dlhub_sdk->-r MAST-ML/requirements.txt (line 2)) (0.5.1)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect; sys_platform != \"win32\"->ipython>=4.0.0->ipykernel->parsl==0.9.0->funcx>=0.0.5->dlhub_sdk->-r MAST-ML/requirements.txt (line 2)) (0.7.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0->ipykernel->parsl==0.9.0->funcx>=0.0.5->dlhub_sdk->-r MAST-ML/requirements.txt (line 2)) (0.2.5)\n","Building wheels for collected packages: pymatgen\n","  Building wheel for pymatgen (PEP 517) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pymatgen: filename=pymatgen-2022.0.5-cp37-cp37m-linux_x86_64.whl size=3792021 sha256=00ed23ca986c55bcc8d9d44f6ed7930f0674f6c9270710f15c8abafea06bdcdd\n","  Stored in directory: /root/.cache/pip/wheels/c7/6c/74/b93186a11fe286a09dc9230ddbe5816ab24405993bdfa7c20a\n","Successfully built pymatgen\n","Building wheels for collected packages: citrination-client, matminer, pypif, future, configobj\n","  Building wheel for citrination-client (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for citrination-client: filename=citrination_client-6.5.1-py2.py3-none-any.whl size=116097 sha256=b8c329db43f5d3df4329b326bebca1023a8001f0a1a7f4c456f4617198111787\n","  Stored in directory: /root/.cache/pip/wheels/6c/88/f5/5a3d5759228aabc63cb3baf2d767369ac99d18f3a941d381e7\n","  Building wheel for matminer (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for matminer: filename=matminer-0.6.5-cp37-none-any.whl size=1189789 sha256=689993ff55d8a4bcf93b78fc0902ebd0313b365567c4d6717ac4cd5edaf7225f\n","  Stored in directory: /root/.cache/pip/wheels/b9/d9/ca/b03a29a28fb675c253a5792995097c48c25b8d409ddac4e2c1\n","  Building wheel for pypif (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pypif: filename=pypif-2.1.2-py2.py3-none-any.whl size=29506 sha256=a7cff7c239c93889ce05a8a595ebeea09cc62ebcf10c496c564efe8f81d2860c\n","  Stored in directory: /root/.cache/pip/wheels/0d/19/de/9d99bb147337e90a209a44c89e67b3aaadcac4f6f8d106c13d\n","  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for future: filename=future-0.18.2-cp37-none-any.whl size=491058 sha256=9b0af96f630a6a78057ded2e0398988d46898249a77da850e0a92a6a1f43785e\n","  Stored in directory: /root/.cache/pip/wheels/8b/99/a0/81daf51dcd359a9377b110a8a886b3895921802d2fc1b2397e\n","  Building wheel for configobj (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for configobj: filename=configobj-5.0.6-cp37-none-any.whl size=34547 sha256=6c35d8ddcb913e89364815ed197d2cf7e011a55c084cdecceda238aafe80b3f6\n","  Stored in directory: /root/.cache/pip/wheels/f1/e4/16/4981ca97c2d65106b49861e0b35e2660695be7219a2d351ee0\n","Successfully built citrination-client matminer pypif future configobj\n","\u001b[31mERROR: nbclient 0.5.3 has requirement jupyter-client>=6.1.5, but you'll have jupyter-client 5.3.5 which is incompatible.\u001b[0m\n","\u001b[31mERROR: dlhub-sdk 0.9.4 has requirement requests>=2.24.0, but you'll have requests 2.23.0 which is incompatible.\u001b[0m\n","\u001b[31mERROR: pymatgen 2022.0.5 has requirement numpy>=1.20.1, but you'll have numpy 1.19.5 which is incompatible.\u001b[0m\n","\u001b[31mERROR: pymatgen 2022.0.5 has requirement scipy>=1.5.0, but you'll have scipy 1.4.1 which is incompatible.\u001b[0m\n","\u001b[31mERROR: matminer 0.6.5 has requirement scikit-learn>=0.23.1, but you'll have scikit-learn 0.22.2.post1 which is incompatible.\u001b[0m\n","Installing collected packages: pypif, pyyaml, citrination-client, jsonschema, sphinx-rtd-theme, texttable, pynacl, cryptography, bcrypt, paramiko, ipyparallel, pyjwt, globus-sdk, psutil, parsl, lockfile, python-daemon, typer, configobj, fair-research-login, nbsphinx, funcx, globus-nexus-client, mdf-toolbox, dlhub-sdk, future, uncertainties, monty, ruamel.yaml.clib, ruamel.yaml, plotly, spglib, pymatgen, tqdm, pint, matminer, mdf-forge, pyaml, scikit-optimize, sphinx-automodapi\n","  Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","  Found existing installation: jsonschema 2.6.0\n","    Uninstalling jsonschema-2.6.0:\n","      Successfully uninstalled jsonschema-2.6.0\n","  Found existing installation: psutil 5.4.8\n","    Uninstalling psutil-5.4.8:\n","      Successfully uninstalled psutil-5.4.8\n","  Found existing installation: future 0.16.0\n","    Uninstalling future-0.16.0:\n","      Successfully uninstalled future-0.16.0\n","  Found existing installation: plotly 4.4.1\n","    Uninstalling plotly-4.4.1:\n","      Successfully uninstalled plotly-4.4.1\n","  Found existing installation: tqdm 4.41.1\n","    Uninstalling tqdm-4.41.1:\n","      Successfully uninstalled tqdm-4.41.1\n","Successfully installed bcrypt-3.2.0 citrination-client-6.5.1 configobj-5.0.6 cryptography-3.4.6 dlhub-sdk-0.9.4 fair-research-login-0.2.0 funcx-0.0.5 future-0.18.2 globus-nexus-client-0.3.0 globus-sdk-2.0.1 ipyparallel-6.3.0 jsonschema-3.2.0 lockfile-0.12.2 matminer-0.6.5 mdf-forge-0.7.6 mdf-toolbox-0.5.7 monty-2021.3.3 nbsphinx-0.8.2 paramiko-2.7.2 parsl-0.9.0 pint-0.17 plotly-4.14.3 psutil-5.8.0 pyaml-20.4.0 pyjwt-1.7.1 pymatgen-2022.0.5 pynacl-1.4.0 pypif-2.1.2 python-daemon-2.3.0 pyyaml-5.4.1 ruamel.yaml-0.16.13 ruamel.yaml.clib-0.2.2 scikit-optimize-0.8.1 spglib-1.16.1 sphinx-automodapi-0.13 sphinx-rtd-theme-0.5.1 texttable-1.6.3 tqdm-4.59.0 typer-0.3.2 uncertainties-3.1.5\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["psutil"]}}},"metadata":{"tags":[]}},{"output_type":"stream","text":["Collecting pymatgen==2020.12.31\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e1/18/274b40cff34257a728071199d21105ced3116b42dd60793113eee7b1b5ca/pymatgen-2020.12.31.tar.gz (2.8MB)\n","\u001b[K     |████████████████████████████████| 2.8MB 5.6MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.14.3 in /usr/local/lib/python3.7/dist-packages (from pymatgen==2020.12.31) (1.19.5)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pymatgen==2020.12.31) (2.23.0)\n","Requirement already satisfied: ruamel.yaml>=0.15.6 in /usr/local/lib/python3.7/dist-packages (from pymatgen==2020.12.31) (0.16.13)\n","Requirement already satisfied: monty>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from pymatgen==2020.12.31) (2021.3.3)\n","Collecting scipy>=1.5.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b6/3a/9e0649ab2d5ade703baa70ef980aa08739226e5d6a642f084bb201a92fc2/scipy-1.6.1-cp37-cp37m-manylinux1_x86_64.whl (27.4MB)\n","\u001b[K     |████████████████████████████████| 27.4MB 159kB/s \n","\u001b[?25hRequirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from pymatgen==2020.12.31) (0.8.9)\n","Requirement already satisfied: spglib>=1.9.9.44 in /usr/local/lib/python3.7/dist-packages (from pymatgen==2020.12.31) (1.16.1)\n","Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.7/dist-packages (from pymatgen==2020.12.31) (2.5)\n","Requirement already satisfied: matplotlib>=1.5 in /usr/local/lib/python3.7/dist-packages (from pymatgen==2020.12.31) (3.2.2)\n","Requirement already satisfied: palettable>=3.1.1 in /usr/local/lib/python3.7/dist-packages (from pymatgen==2020.12.31) (3.3.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.7/dist-packages (from pymatgen==2020.12.31) (1.7.1)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from pymatgen==2020.12.31) (1.1.5)\n","Requirement already satisfied: plotly>=4.5.0 in /usr/local/lib/python3.7/dist-packages (from pymatgen==2020.12.31) (4.14.3)\n","Requirement already satisfied: uncertainties>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from pymatgen==2020.12.31) (3.1.5)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pymatgen==2020.12.31) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pymatgen==2020.12.31) (2020.12.5)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->pymatgen==2020.12.31) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pymatgen==2020.12.31) (2.10)\n","Requirement already satisfied: ruamel.yaml.clib>=0.1.2; platform_python_implementation == \"CPython\" and python_version < \"3.10\" in /usr/local/lib/python3.7/dist-packages (from ruamel.yaml>=0.15.6->pymatgen==2020.12.31) (0.2.2)\n","Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from networkx>=2.2->pymatgen==2020.12.31) (4.4.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.5->pymatgen==2020.12.31) (0.10.0)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.5->pymatgen==2020.12.31) (2.8.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.5->pymatgen==2020.12.31) (1.3.1)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.5->pymatgen==2020.12.31) (2.4.7)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.7/dist-packages (from sympy->pymatgen==2020.12.31) (1.2.1)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->pymatgen==2020.12.31) (2018.9)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from plotly>=4.5.0->pymatgen==2020.12.31) (1.15.0)\n","Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.7/dist-packages (from plotly>=4.5.0->pymatgen==2020.12.31) (1.3.3)\n","Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from uncertainties>=3.1.4->pymatgen==2020.12.31) (0.18.2)\n","Building wheels for collected packages: pymatgen\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"I93RLdVb5kl3"},"source":["Now we'll sync Colab with our google drive so that we can save directly our outputs to google drive. If you haven't already I recommend making a folder in google drive titled \"MASTML_colab\" or something similar to direct all your results towards. Going forward I'll assume this folder exists and I'll base the runs out of that folder. If you want to change the naming that can work as well as long as you update when that location is referenced."]},{"cell_type":"code","metadata":{"id":"w-jHgEAFquSh","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1616446255311,"user_tz":300,"elapsed":9434,"user":{"displayName":"HAIRONG YIN","photoUrl":"","userId":"16460850665293890760"}},"outputId":"1b97c1e5-0d58-4afd-bc91-a58e36026735"},"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"_PbyGFIU6B7Q"},"source":["We need to add the MAST-ML folder to our sys path so that python can find the modules\n"]},{"cell_type":"code","metadata":{"id":"nwQO48j1ws3S","executionInfo":{"status":"ok","timestamp":1616446263679,"user_tz":300,"elapsed":322,"user":{"displayName":"HAIRONG YIN","photoUrl":"","userId":"16460850665293890760"}}},"source":["import sys\n","sys.path.append('MAST-ML')"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Oe2e3F-x6EZz"},"source":["Here we import the MAST-ML modules used. Note that if you're making edits you may have to come back to update these imports to grab new functionality that isn't included here."]},{"cell_type":"code","metadata":{"id":"x8GIei1qQoWL","colab":{"base_uri":"https://localhost:8080/","height":498},"executionInfo":{"status":"error","timestamp":1616446296724,"user_tz":300,"elapsed":371,"user":{"displayName":"HAIRONG YIN","photoUrl":"","userId":"16460850665293890760"}},"outputId":"2edabc51-ab13-42cd-d08f-dde9497c029b"},"source":["\n","from mastml.mastml import Mastml\n","from mastml.datasets import LocalDatasets, DataCleaning\n","from mastml.preprocessing import SklearnPreprocessor\n","from mastml.models import SklearnModel\n","from mastml.data_splitters import SklearnDataSplitter, NoSplit\n","from mastml.feature_selectors import EnsembleModelFeatureSelector, NoSelect\n","from mastml.feature_generators import ElementalFeatureGenerator\n","from mastml.hyper_opt import GridSearch"],"execution_count":18,"outputs":[{"output_type":"error","ename":"ImportError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)","\u001b[0;32m<ipython-input-18-e93449b16edb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmastml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_splitters\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSklearnDataSplitter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoSplit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmastml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_selectors\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEnsembleModelFeatureSelector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoSelect\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmastml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_generators\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mElementalFeatureGenerator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmastml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhyper_opt\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGridSearch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/MAST-ML/mastml/feature_generators.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatminer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmatminer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeaturizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstructure\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatminer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeaturizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msite\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatminer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeaturizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomposition\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mElementProperty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOxidationStates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matminer/featurizers/structure.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmonty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdev\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrequires\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpymatgen\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStructure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLattice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpymatgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manalysis\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbond_valence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpymatgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manalysis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiffraction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxrd\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mXRDCalculator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mImportError\u001b[0m: cannot import name 'Structure' from 'pymatgen' (unknown location)","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"]}]},{"cell_type":"markdown","metadata":{"id":"oyt61i7J6kmc"},"source":["And finally we'll import pandas to help with handling dataframes throughout the notebook."]},{"cell_type":"code","metadata":{"id":"QasqdefdEh7n","executionInfo":{"status":"aborted","timestamp":1616446268456,"user_tz":300,"elapsed":2900,"user":{"displayName":"HAIRONG YIN","photoUrl":"","userId":"16460850665293890760"}}},"source":["import pandas as pd"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"P7s6xyjq6zxv"},"source":["## Section 2: Data Cleaning\n","\n","\n","---\n","this section is largely the same as the previous notebook in functionality.\n","We'll read in the same initial bandgap data we used in the previous notebook then perform the same cleaning steps:  \n","1) Filtering for \"Reliability\"  \n","2) Averaging bandgap values where we have duplicates  \n"]},{"cell_type":"markdown","metadata":{"id":"AkmW1QuL8ci9"},"source":["Read in the band gap data from our dataset. If you haven't already upload the bandgap_data_v2.csv data to the MASTML_colab folder"]},{"cell_type":"code","metadata":{"id":"185olJA6EWgH","executionInfo":{"status":"aborted","timestamp":1616446268457,"user_tz":300,"elapsed":1879,"user":{"displayName":"HAIRONG YIN","photoUrl":"","userId":"16460850665293890760"}}},"source":["mastml_df = pd.read_csv(\"./drive/MyDrive/MASTML_colab/bandgap_data_v2.csv\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PDkWyHHx8pSr"},"source":["Filter for only Reliability 1"]},{"cell_type":"code","metadata":{"id":"G2STcYIzFl31","executionInfo":{"status":"aborted","timestamp":1616446268458,"user_tz":300,"elapsed":1308,"user":{"displayName":"HAIRONG YIN","photoUrl":"","userId":"16460850665293890760"}}},"source":["mastml_df_filtered = mastml_df[mastml_df[\"Reliability\"]==1]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DE8ygBOx8tr-"},"source":["Define the averaging function used previously in the nanohub notebook. Note that this wasn't explicitly in the previous notebook as it was being imported from a seperate script file with some of these helpep functions. but here we'll just define it locally in the notebook"]},{"cell_type":"code","metadata":{"id":"x9eHbyxRFrt8","executionInfo":{"status":"aborted","timestamp":1616446268459,"user_tz":300,"elapsed":880,"user":{"displayName":"HAIRONG YIN","photoUrl":"","userId":"16460850665293890760"}}},"source":["def average_bandgaps(master_df, input_col_header, output_col_header):\n","    for chem_formula in master_df[input_col_header].unique():\n","        temp_df = master_df[master_df[input_col_header]==chem_formula].copy()\n","        if len(temp_df) > 1:\n","            avg_bandgap = temp_df[output_col_header].mean()\n","            indexes = temp_df.index\n","            master_df.at[indexes,output_col_header] = avg_bandgap\n","    master_df_clean = master_df.drop_duplicates(subset=input_col_header)\n","    return master_df_clean"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pinx2EEU88jt"},"source":["We then call the function to do the same bandgap averaging when we have duplicates in the dataset."]},{"cell_type":"code","metadata":{"id":"dVywI4h5GpCF","colab":{"base_uri":"https://localhost:8080/","height":168},"executionInfo":{"status":"error","timestamp":1616446268957,"user_tz":300,"elapsed":980,"user":{"displayName":"HAIRONG YIN","photoUrl":"","userId":"16460850665293890760"}},"outputId":"12f01994-b988-4bef-b0c6-ff45ac44dabb"},"source":["mastml_df_clean = average_bandgaps(mastml_df_filtered, 'chemicalFormula Clean', 'Band gap values Clean')"],"execution_count":7,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-35d884088d86>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmastml_df_clean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maverage_bandgaps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmastml_df_filtered\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'chemicalFormula Clean'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Band gap values Clean'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'average_bandgaps' is not defined"]}]},{"cell_type":"markdown","metadata":{"id":"2QtQtIOd9Cpd"},"source":["This section is new. We reset the index to match the previous notebook so that we can explicitly define the same Train / Test split that we used before. The test_indices object is just a hard copied list of the index values from the previous notebook. If you want to go check them you can find the X_test object and call X_test.index to see these yourself."]},{"cell_type":"code","metadata":{"id":"7kaM8janNfaH","colab":{"base_uri":"https://localhost:8080/","height":185},"executionInfo":{"status":"error","timestamp":1616446269349,"user_tz":300,"elapsed":978,"user":{"displayName":"HAIRONG YIN","photoUrl":"","userId":"16460850665293890760"}},"outputId":"045315d4-ca68-49ec-89b2-1c8c24db6ebe"},"source":["mastml_df_clean.reset_index(inplace=True)\n","mastml_df_clean.drop(columns='level_0',inplace=True)"],"execution_count":8,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-a85357b0aedc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmastml_df_clean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmastml_df_clean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'level_0'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'mastml_df_clean' is not defined"]}]},{"cell_type":"code","metadata":{"id":"nDVtUAEyP7KO","executionInfo":{"status":"ok","timestamp":1616446269947,"user_tz":300,"elapsed":1401,"user":{"displayName":"HAIRONG YIN","photoUrl":"","userId":"16460850665293890760"}}},"source":["test_indices = [279, 168, 192,  33, 223,  22, 341, 453, 460, 455, 120, 430, 436,\n","            366, 292, 278, 163, 216, 420, 210, 214, 422, 340,  41, 416, 146,\n","            280, 229, 300, 111, 407, 250, 379,  20, 356,   4, 141, 139, 121,\n","            324, 147, 415,  57, 301, 393, 454,  30]"],"execution_count":9,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IQWI9X0A9e9D"},"source":["Finally we define a new column \"testdata\" which is going to be a binary column that is either 0 for \"not testing data\" or 1 for \"is testing data\". This is what we can feed into MAST-ML to explicitly define a set of Test data that is held out from all training."]},{"cell_type":"code","metadata":{"id":"Q4FJiTWAQt_K","colab":{"base_uri":"https://localhost:8080/","height":168},"executionInfo":{"status":"error","timestamp":1616446269949,"user_tz":300,"elapsed":1016,"user":{"displayName":"HAIRONG YIN","photoUrl":"","userId":"16460850665293890760"}},"outputId":"e5a0f759-4112-432a-fdab-82ef1a5bb3a8"},"source":["mastml_df_clean[\"testdata\"]=0"],"execution_count":10,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-10-46ae302b7c09>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmastml_df_clean\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"testdata\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'mastml_df_clean' is not defined"]}]},{"cell_type":"code","metadata":{"id":"crO7RhFwQcJf","colab":{"base_uri":"https://localhost:8080/","height":185},"executionInfo":{"status":"error","timestamp":1616446269950,"user_tz":300,"elapsed":801,"user":{"displayName":"HAIRONG YIN","photoUrl":"","userId":"16460850665293890760"}},"outputId":"09b1da55-d4f9-4fbd-f767-766845fd67cc"},"source":["for idx in test_indices:\n","  mastml_df_clean.at[idx,'testdata']=1"],"execution_count":11,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-b0ed0a544560>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_indices\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mmastml_df_clean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'testdata'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'mastml_df_clean' is not defined"]}]},{"cell_type":"code","metadata":{"id":"S4wpDg0zJAQN","colab":{"base_uri":"https://localhost:8080/","height":185},"executionInfo":{"status":"error","timestamp":1616446270450,"user_tz":300,"elapsed":1155,"user":{"displayName":"HAIRONG YIN","photoUrl":"","userId":"16460850665293890760"}},"outputId":"14504cd0-eb2c-4ff7-94e8-8e04f27c5fa2"},"source":["output_path = \"./drive/MyDrive/MASTML_colab/bandgap_data_v3.csv\"\n","mastml_df_clean.to_csv(output_path,index=False)"],"execution_count":12,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-12-6ecf66a0244e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0moutput_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"./drive/MyDrive/MASTML_colab/bandgap_data_v3.csv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmastml_df_clean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'mastml_df_clean' is not defined"]}]},{"cell_type":"markdown","metadata":{"id":"AEQqAql19ybB"},"source":["Notice how in the initial data cleaning and configuration there is still a bit that we do outside of MAST-ML. While MAST-ML gives a good deal of flexibility and useful tools for performing these machine learning workflows there will often still be custom steps like this that get added to the overall workflow that varies dataset by dataset."]},{"cell_type":"markdown","metadata":{"id":"fcWk1k177SWM"},"source":["## Section 3: Initializing MAST-ML\n","---\n","Now we'll dive into interacting more directly with the MAST-ML software. The first thing we need to do is setup some of the baseline information that MASTML will use as we call different sections of the code. This is similar to the [general] section from the previous configuration file oriented code base.\n"]},{"cell_type":"markdown","metadata":{"id":"dsRqGRLs_IXU"},"source":["Set the name of the savepath to save MAST-ML results to. It's recommended to make this a unique name each time you come back to this notebook. That way all the outputs you get from each session will be in a unique location that's easier to come back to later.\n","\n","By default I've set the output to the \"nanohub_workflow\" folder under our colab folder."]},{"cell_type":"code","metadata":{"id":"Xf8MFHjlM7Oe","executionInfo":{"status":"ok","timestamp":1616446270789,"user_tz":300,"elapsed":754,"user":{"displayName":"HAIRONG YIN","photoUrl":"","userId":"16460850665293890760"}}},"source":["SAVEPATH = 'drive/MyDrive/MASTML_colab/Nanohub_workflow'\n","\n","mastml = Mastml(savepath=SAVEPATH)\n","savepath = mastml.get_savepath"],"execution_count":13,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"I359kFP2_wpk"},"source":["With MAST-ML initialized you should see your output directory created. You can check this using the file tree on the left of the screen or directly through google drive.\n","\n","Next up we need to define the configuration of our Data file that we setup earlier. We'll define the names for all of the key components:  \n","target: the target variable that we want to predict  \n","extra_columns: the metadata columns that aren't features but we still want to keep track off  \n","testdata_columns: the column with binary values defining what is and isn't test data  \n","group_column: column names specifying unique groups in the data. We don't use this during this workflow  \n","as_frame: determines the structure of outputs. True gives up dataframe outputs that are easier to read in the notebook"]},{"cell_type":"code","metadata":{"id":"kWxrG-RgxeTA","colab":{"base_uri":"https://localhost:8080/","height":413},"executionInfo":{"status":"error","timestamp":1616446271063,"user_tz":300,"elapsed":680,"user":{"displayName":"HAIRONG YIN","photoUrl":"","userId":"16460850665293890760"}},"outputId":"a56955dd-ec7a-4ea5-aef1-2398fb765fec"},"source":["target = 'Band gap values Clean'\n","extra_columns = ['index', 'Band gap units', 'Band gap method', 'Reliability','chemicalFormula Clean']\n","testdata_columns = ['testdata']\n","\n","# calling the LocalDatasets section of the code initializes this section which we then execute with the method below\n","d = LocalDatasets(file_path='./drive/MyDrive/MASTML_colab/bandgap_data_v3.csv', \n","                  target=target, \n","                  extra_columns=extra_columns, \n","                  group_column=None,\n","                  testdata_columns=testdata_columns,\n","                  as_frame=True)\n","\n","# Load the data with the load_data() method\n","data_dict = d.load_data()"],"execution_count":14,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-14-593209509e13>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Load the data with the load_data() method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mdata_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/content/MAST-ML/mastml/datasets.py\u001b[0m in \u001b[0;36mload_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;31m# Import data from file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0;31m# Assign default values to input_features and target_feature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/MAST-ML/mastml/datasets.py\u001b[0m in \u001b[0;36m_import\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mext\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'.csv'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m             \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mext\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'.xlsx'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    686\u001b[0m     )\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    946\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   2008\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2010\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2011\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './drive/MyDrive/MASTML_colab/bandgap_data_v3.csv'"]}]},{"cell_type":"markdown","metadata":{"id":"S07AJOwqBZbc"},"source":["Let's take a second to look through what just happened. In the previous cell the \"data_dict\" object was defined. It is a dictionary of various things that were loaded in from the dataseet. We'll pull those out of the dictionary to set them all to unique objects."]},{"cell_type":"markdown","metadata":{"id":"XT7AuA-mBuh9"},"source":["We see there are 5 keys:  \n","  X: the X feature matrix (used to fit the ML model). notice this is empty becausee we haven't done any feature generation  \n","  y: the y target data vector (true values)  \n","  X_extra: matrix of meta data not used in fitting (i.e. not part of X or y)  \n","  groups: vector of group labels. empty because we didn't set it  \n","  X_testdata: matrix or vector of left out data indices"]},{"cell_type":"code","metadata":{"id":"Nrx-OGW3_dap","colab":{"base_uri":"https://localhost:8080/","height":168},"executionInfo":{"status":"error","timestamp":1616446274515,"user_tz":300,"elapsed":3184,"user":{"displayName":"HAIRONG YIN","photoUrl":"","userId":"16460850665293890760"}},"outputId":"b9a69db3-fef9-4a9d-d3bd-c8788f4ec345"},"source":["data_dict.keys()"],"execution_count":15,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-15-d7e9e6ce6848>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'data_dict' is not defined"]}]},{"cell_type":"code","metadata":{"id":"a-Lrm2lG_7hi","colab":{"base_uri":"https://localhost:8080/","height":236},"executionInfo":{"status":"error","timestamp":1616446275308,"user_tz":300,"elapsed":3887,"user":{"displayName":"HAIRONG YIN","photoUrl":"","userId":"16460850665293890760"}},"outputId":"0785bf60-33dd-42df-ff9d-e7c80fcec897"},"source":["X = data_dict['X']\n","y = data_dict['y']\n","X_extra = data_dict['X_extra']\n","groups = data_dict['groups']\n","X_testdata = data_dict['X_testdata']"],"execution_count":16,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-16-36ab436fd9fd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'X'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'y'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mX_extra\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'X_extra'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mgroups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'groups'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mX_testdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'X_testdata'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'data_dict' is not defined"]}]},{"cell_type":"code","metadata":{"id":"pR-pTG-Zx-AW","executionInfo":{"status":"aborted","timestamp":1616446275305,"user_tz":300,"elapsed":3800,"user":{"displayName":"HAIRONG YIN","photoUrl":"","userId":"16460850665293890760"}}},"source":["X"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DDRPN14syAue","executionInfo":{"status":"aborted","timestamp":1616446275305,"user_tz":300,"elapsed":3705,"user":{"displayName":"HAIRONG YIN","photoUrl":"","userId":"16460850665293890760"}}},"source":["groups"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VuKB49u_yM9c","executionInfo":{"status":"aborted","timestamp":1616446275306,"user_tz":300,"elapsed":3620,"user":{"displayName":"HAIRONG YIN","photoUrl":"","userId":"16460850665293890760"}}},"source":["X_extra"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_jdQjcY5yN6z","executionInfo":{"status":"aborted","timestamp":1616446275306,"user_tz":300,"elapsed":3553,"user":{"displayName":"HAIRONG YIN","photoUrl":"","userId":"16460850665293890760"}}},"source":["X_testdata"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Wg9RjtoaEP9Z"},"source":["## Section 4: Reproducing Key Workflow Steps\n","---\n","Now we'll start to dive into reproducing the key workflow steps from the previous notebook. These are:  \n","1) Feature Generation  \n","2) Feature Engineering  \n","3) Model Assessment and Training  \n","4) Model Optimization  \n","5) Model Predictions"]},{"cell_type":"markdown","metadata":{"id":"Jj5kqXFTCHXl"},"source":["If the data contains missing values (this one doesn't), we can clean the data with the built in tools in MAST-ML, which corrects missing values and provides some basic analysis of the input data. Since there are no missing values the data cleaner will still output some useful plots and statistics of our input data."]},{"cell_type":"code","metadata":{"id":"YgQJg2fDyQRU","executionInfo":{"status":"aborted","timestamp":1616446275307,"user_tz":300,"elapsed":3273,"user":{"displayName":"HAIRONG YIN","photoUrl":"","userId":"16460850665293890760"}}},"source":["cleaner = DataCleaning()\n","X, y = cleaner.evaluate(X=X, \n","                        y=y, \n","                        method='imputation', \n","                        strategy='mean', \n","                        savepath=savepath)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IzuXHap6CYgy"},"source":["Looking at the format of the DataCleaning section also highlights the key way we will interact with MAST-ML in this format. For each section of the code we want to use we'll initialize it using what's called a class name, in this case \"DataCleaning\", and then call the \"evaluate\" method to essentially run the code for that Class.\n","\n","Let's look through the outputs and compare them to some of the initial dataset analysis and compare to the previous Nanohub workflow. Open the \"histogram_target_values.png\" file in the newly created DataCleaning folder under our output directory. Compare back to the histogram we made in the previous notebook. Are they the same?\n","\n","This is the type of check we would do to make sure we aren't missing any data switching between the two platforms."]},{"cell_type":"markdown","metadata":{"id":"O0cJ9kJAFMyd"},"source":["Next is generating the elemental features used in the model. Just like the previous step we define the class of feature generation we want to use, and then call the evaluate method. Again results are output to a new folder with the name of the Class that was evaluated. The features are also added to the X object so we can continue to use them directly without having to read in from the generated files.\n","\n","You can see from the output that MAST-ML is also performing some basic feature engineering by dropping features that are missing values. This is the most basic way of handling missing values, and if we wanted to do something more complex later we could come back and use imputation to fill in those missing values instead."]},{"cell_type":"code","metadata":{"id":"4Si2f98-cY6u","executionInfo":{"status":"aborted","timestamp":1616446275307,"user_tz":300,"elapsed":3027,"user":{"displayName":"HAIRONG YIN","photoUrl":"","userId":"16460850665293890760"}}},"source":["generator = ElementalFeatureGenerator(composition_df = X_extra[\"chemicalFormula Clean\"],\n","                      feature_types='composition_avg',\n","                      remove_constant_columns=True)\n","X, y = generator.evaluate(X = X,\n","                          y = y,\n","                          savepath = savepath)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4vvs0Gd6GEnu"},"source":["Using the cell block below with outputs the feature object directly compare the features generated to those in the previous workflow. Do we have the same total number?\n","\n","If they're different can you think of any reasons why?  \n","hint: mastml does some initial cleaning automatically on the features."]},{"cell_type":"code","metadata":{"id":"8LrJ6AX7hrpM","colab":{"base_uri":"https://localhost:8080/","height":168},"executionInfo":{"status":"error","timestamp":1616446275433,"user_tz":300,"elapsed":2960,"user":{"displayName":"HAIRONG YIN","photoUrl":"","userId":"16460850665293890760"}},"outputId":"5d216d75-7882-4e62-f61c-94628f186e94"},"source":["X"],"execution_count":17,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-17-b5fec669aca1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"]}]},{"cell_type":"markdown","metadata":{"id":"m5ITre4zHYxf"},"source":["Next we'll see one of the benefits of using MAST-ML in this new way. Currently we don't have the same method impelemented in MAST-ML to remove highly correlated features. Previously adding this in would have been a good deal of work. But because we're using MAST-ML in this interactive notebook environment we can add in our own feature engineering steps that aren't included in the MAST-ML software. Below I just copied over the code from the previous notebook to filter highly correlated features"]},{"cell_type":"code","metadata":{"id":"YIQTsE-0HzQV","executionInfo":{"status":"aborted","timestamp":1616446275427,"user_tz":300,"elapsed":2784,"user":{"displayName":"HAIRONG YIN","photoUrl":"","userId":"16460850665293890760"}}},"source":["import numpy as np"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PkM9M1aoGydV","executionInfo":{"status":"aborted","timestamp":1616446275428,"user_tz":300,"elapsed":2729,"user":{"displayName":"HAIRONG YIN","photoUrl":"","userId":"16460850665293890760"}}},"source":["features_corr_df = X.corr(method=\"pearson\").abs()\n","# Filter the features with correlation coefficients above 0.95\n","upper = features_corr_df.where(np.triu(np.ones(features_corr_df.shape), k=1).astype(np.bool))\n","to_drop = [column for column in upper.columns if any(upper[column] > 0.95)]\n","X = X.drop(columns=to_drop)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8L0jiPv1H4Cc","executionInfo":{"status":"aborted","timestamp":1616446275428,"user_tz":300,"elapsed":2652,"user":{"displayName":"HAIRONG YIN","photoUrl":"","userId":"16460850665293890760"}}},"source":["X"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GXzjcRTxIJ7p"},"source":["Next up we perform the last feature engineering step, which was to normalize the features using scikit-learn's MinMaxScaler method. "]},{"cell_type":"code","metadata":{"id":"0RxphS-Zivb0","executionInfo":{"status":"aborted","timestamp":1616446275429,"user_tz":300,"elapsed":2498,"user":{"displayName":"HAIRONG YIN","photoUrl":"","userId":"16460850665293890760"}}},"source":["preprocessor = SklearnPreprocessor(preprocessor='MinMaxScaler', as_frame=True)\n","X = preprocessor.evaluate(X=X,\n","                          y=y, \n","                          savepath=savepath)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UDtU0nbmIaUO"},"source":["With our features setup now we jump into training, and evaluating models. This section is a bit more complex as we're defining multiple things at once. Things we define at the top of the cell are:  \n","1) The model or models to use. These need to be in list format which is why you see them in square brackets.  \n","2) A potential feature selector. Here we don't use one to mirror the previous workflow.  \n","3) Assessment metrics. We specify a range of them.  \n","4) A Splitter to use. The splitter is the class that we'll call in the bottom half and defines what kind of splits in the dataset we want to make. Recall that we previously established our Test set of data. So for this first test of the \"default model\" we don't need to make any additional splits which is why we use the NoSplit() class"]},{"cell_type":"code","metadata":{"id":"-ZryaRKb1cy-","executionInfo":{"status":"aborted","timestamp":1616446275429,"user_tz":300,"elapsed":2325,"user":{"displayName":"HAIRONG YIN","photoUrl":"","userId":"16460850665293890760"}}},"source":["default_decisiontree = SklearnModel(model='DecisionTreeRegressor')\n","models = [default_decisiontree]\n","selector = [NoSelect()]\n","metrics = ['r2_score', 'mean_absolute_error', 'root_mean_squared_error', 'rmse_over_stdev']\n","\n","splitter = NoSplit()\n","splitter.evaluate(X=X,\n","                  y=y, \n","                  models=models,\n","                  preprocessor=None,\n","                  selectors=selector,\n","                  metrics=metrics,\n","                  savepath=savepath,\n","                  X_extra=X_extra,\n","                  leaveout_inds=X_testdata,\n","                  verbosity=3)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aGxkfJa-KIOO"},"source":["After this run completes we want to go look at how the model is performing. Navigate to the newly created \"DecisionTreeRegressor...\" folder and find both the \"parity_plot_leaveout.png\" file as well as the \"parity_plot_train.png\" file. Compare them both to eachother as well as to the parity plots made during the Nanohub notebook for the default model. Are they the same? Similar?  \n","\n","Note that the model type used is technically different. Previously we used a RandomForest with 1 tree which very closely mimics a sigle decision tree, and this time we explicitly used the decisiontreeregressor from scikit-learn."]},{"cell_type":"markdown","metadata":{"id":"lTe5_pQoyW8H"},"source":["Next we'll reproduce the model hyperparameter optimization we previously performed. Most things stay very similar but we switch to the Random Forest model so we can increase the number of trees again, and we need to add a new option to the splitter evaluate call which is the \"GridSearch\" class in mastml. This mirrors the same gridsearchcv call that is made in the previous nanohub notebook, however the format is slightly different.  \n","\n","For the GridSearch class we need to specify:  \n","1) param_names: the hyperparameters to grid over  \n","2) param_values: a string which specifies the grid. \n","\n","This follows the format of a linspace or logspace command in programs like matlab, or python packages like Numpy. the numbers in the string specify the starting value, ending value, and then number of points in between. Then we can give two options after which are lin/log which specifies whether the numbers are in linear space or log space. log space means we are specifying the exponent (10^x). And the last option is the type of number with int or float being the two most common versions. Some Hyperparametes need to be integers.\n","\n","3) scoring: a string specifying the score function to use."]},{"cell_type":"code","metadata":{"id":"rK89SsGzLvAe","executionInfo":{"status":"aborted","timestamp":1616446275430,"user_tz":300,"elapsed":2061,"user":{"displayName":"HAIRONG YIN","photoUrl":"","userId":"16460850665293890760"}}},"source":["default_RF = SklearnModel(model='RandomForestRegressor')\n","models = [default_RF]\n","selector = [NoSelect()]\n","metrics = ['r2_score', 'mean_absolute_error', 'root_mean_squared_error', 'rmse_over_stdev']\n","grid1 = GridSearch(param_names='n_estimators',param_values='2 50 5 lin int',scoring='neg_mean_squared_error')\n","grids = [grid1]\n","splitter = NoSplit()\n","splitter.evaluate(X=X,\n","                  y=y, \n","                  models=models,\n","                  preprocessor=None,\n","                  selectors=selector,\n","                  metrics=metrics,\n","                  savepath=savepath,\n","                  X_extra=X_extra,\n","                  leaveout_inds=X_testdata,\n","                  hyperopts = grids,\n","                  recalibrate_errors = True,\n","                  verbosity=3)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JkeTDgt60PPz"},"source":["With the optimization run complete again we'll look through our outputs to find the results. Go into the new RandomForesRegressor folder and then into split_outer_0/split_0 and find the \"grid search\" files. One of them has the best identified hyperparameters, and the other give the full results for all options tried. \n","\n","Do the results match the previous gridsearch from the nanohub workflow? meaning do we get the same number of trees as the best?"]},{"cell_type":"markdown","metadata":{"id":"nqgMi85e_8DY"},"source":["The next step is to generate the 5-fold Cross Validation results. Unfortunately it looks like there's a bug with the decision tree currently, so while I set up how that should look it isn't working currently.\n","\n","In the next cell however, with the Random Forest the CV is working correctly so we'll run 5-fold CV with the optimized number of trees from the above hyperparameter grid search."]},{"cell_type":"code","metadata":{"id":"pqvdr6FYuUU-","executionInfo":{"status":"aborted","timestamp":1616446275431,"user_tz":300,"elapsed":1829,"user":{"displayName":"HAIRONG YIN","photoUrl":"","userId":"16460850665293890760"}}},"source":["default_decisiontree = SklearnModel(model='DecisionTreeRegressor')\n","models = [default_decisiontree]\n","selector = [NoSelect()]\n","metrics = ['r2_score', 'mean_absolute_error', 'root_mean_squared_error', 'rmse_over_stdev']\n","\n","splitter = SklearnDataSplitter(splitter='RepeatedKFold', n_repeats=2, n_splits=5)\n","splitter.evaluate(X=X,\n","                  y=y, \n","                  models=models,\n","                  preprocessor=None,\n","                  selectors=selector,\n","                  metrics=metrics,\n","                  savepath=savepath,\n","                  X_extra=X_extra,\n","                  leaveout_inds=X_testdata,\n","                  verbosity=3)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lMxWkitGoiEa","executionInfo":{"status":"aborted","timestamp":1616446275432,"user_tz":300,"elapsed":1753,"user":{"displayName":"HAIRONG YIN","photoUrl":"","userId":"16460850665293890760"}}},"source":["opt_RF = SklearnModel(model='RandomForestRegressor',n_estimators=50)\n","models = [opt_RF]\n","selector = [NoSelect()]\n","metrics = ['r2_score', 'mean_absolute_error', 'root_mean_squared_error', 'rmse_over_stdev']\n","\n","splitter = SklearnDataSplitter(splitter='RepeatedKFold', n_repeats=2, n_splits=5)\n","splitter.evaluate(X=X,\n","                  y=y, \n","                  models=models,\n","                  preprocessor=None,\n","                  selectors=selector,\n","                  metrics=metrics,\n","                  savepath=savepath,\n","                  X_extra=X_extra,\n","                  leaveout_inds=X_testdata,\n","                  recalibrate_errors = True,\n","                  verbosity=3)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"N27RMJB9KwZZ"},"source":["For the predictions section in the Nanohub workflow we used the test data as data to predict. In the MASTML framework all of the predictions are made and named with the convention \"leaveout...\" on the files. To compare how the test data is predicted between MASTML and the previous Nanohub notebook we can compare the predictions in these files to the ones made previously after optimizing the model."]},{"cell_type":"markdown","metadata":{"id":"w4qT_HLFAkHY"},"source":["## Section 5: Modifying the Workflow\n","---\n","\n","And with that we've completed the same steps as previously, using the MASTML code. In doing so we've been able to automatically generate our parity plots, along with a lot of other statistics and plots that we haven't learned about yet. \n","\n","And with this setup we can now do the last step of the activity, in which we can take advantage of the steps we've already established to start to make changes.\n","\n","In the current code we've used the DecisionTreeRegressor and RandomForestRegressor models from scikit-learn. Now choose another model type and repeat the workflow by modifying each step:\n","\n","1) pick another model type from scikit-learn. You can see a reference for available models here: https://scikit-learn.org/stable/supervised_learning.html \n","If you're not sure what kind of model to try I might suggest one of the linear type models such as Ridge Regression or LASSO. To see the list of available hyperparameters for each model you can click their respective link.\n","\n","2) build a default model where you don't change any hyperparameters from the scikit-learn defaults and analyze it's performance both on the Test data and with a 5-fold CV\n","\n","3) perform a grid search on 1 of the hyperparameters. I'd suggest picking the alpha hyperparameters if using one of the linear models suggested above.\n","\n","4) Compare the performance with the optimized hyperparameters. Were you able to improve the performance? how much did the RMSE value decrease for the Test set? How about the 5-fold CV test?"]},{"cell_type":"code","metadata":{"id":"8C7WpP0sBphS","executionInfo":{"status":"aborted","timestamp":1616446275432,"user_tz":300,"elapsed":1548,"user":{"displayName":"HAIRONG YIN","photoUrl":"","userId":"16460850665293890760"}}},"source":[""],"execution_count":null,"outputs":[]}]}